---
title: "modeling terrestrial and arboreal mammals at GPNP"
author: "Gene Estrada"
date: "2024-05-21"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE)

library(tidyverse)
library(vegan)
library(cowplot)
library(coefplot)
library(PerformanceAnalytics)
library(fitdistrplus)
library(MuMIn)
library(sjPlot)
library(factoextra)
library(ggpubr)
library(kableExtra)
library(FD)
library(geosphere)
library(sp)
library(spdep)
library(sf)
library(spmoran)

#mammal observation data - excludes all human observations
m <- read.csv(file = "data/pruned.csv", header = TRUE)
m <- m[,-1]

#adding updated CT location forest type and partition data
ct <- read.csv(file = "data/CTlocations_partitions_May2024.csv", header = TRUE)

#removing lat, long, and habitat designations and adding updated versions
m <- m[,-c(12:14)]
m <- left_join(m, ct[,c("locationID","latitude","longitude","habitat","partition")], by = "locationID")

#ordering forest type
m$habitat <- factor(m$habitat, levels = c("Peat Swamp", "Freshwater Swamp", "Alluvial Bench", 
                                          "Lowland Sandstone", "Lowland Granite", "Upland Granite", "Montane"),
                    ordered = TRUE)
#ordering partitions
m$partition <- factor(m$partition, levels = c("PS1", "FS1", "AB1", "AB2",
                                          "LS1", "LS2","LG1","LG2", "UG1","UG2", "MO1", "MO2"),
                    ordered = TRUE)

#species observation summary table
#species_table <- as.data.frame(table(m$Species, m$habitat))
#species_table <- pivot_wider(species_table, names_from = "Var2", values_from = "Freq")
#colnames(species_table)[colnames(species_table) == 'Var1'] <- 'Species'
#write.csv(species_table, file = "species_observation_table_byFT.csv")

#LiDAR-derived metrics from {FORTLS} and {lidRmetrics}
stand_mets <- read.csv(file = "data/select.stand.mets.csv", header = TRUE)
stand_mets$habitat <- factor(stand_mets$habitat, levels = c("Peat Swamp", "Freshwater Swamp", "Alluvial Bench", 
                                          "Lowland Sandstone", "Lowland Granite", "Upland Granite", "Montane"),
                             ordered = TRUE)
stand_mets$partition <- factor(stand_mets$partition, levels = c("PS1", "FS1", "AB1", "AB2",
                                              "LS1", "LS2","LG1","LG2", "UG1","UG2", "MO1", "MO2"),
                      ordered = TRUE)

#all tree metrics
tree_mets <- read.csv(file = "data/all.tree.mets.csv", header = TRUE)
tree_mets$habitat <- factor(tree_mets$habitat, levels = c("Peat Swamp", "Freshwater Swamp", "Alluvial Bench", 
                                                            "Lowland Sandstone", "Lowland Granite",
                                                          "Upland Granite", "Montane"),
                            ordered = TRUE)
tree_mets$partition <- factor(tree_mets$partition, levels = c("PS1", "FS1", "AB1", "AB2",
                                                                "LS1", "LS2","LG1","LG2", "UG1","UG2", "MO1", "MO2"),
                               ordered = TRUE)
#camera trap metadata
ct_elev <- read.csv(file = "data/cameradata_updatedZJ-ajm.csv", header = TRUE)
ct_elev <- ct_elev[!duplicated(ct_elev$locationID),]

#add CT survey effort data
ct2 <- read.csv(file = "data/ofp_deployments-2021-11-04.csv", header = TRUE)
ct_active_days <- ct2 %>%
  dplyr::select(Deployment.Location.ID, Camera.Deployment.Begin.Date, Camera.Deployment.End.Date) %>%
  mutate(Camera.Deployment.Begin.Date = as.Date(Camera.Deployment.Begin.Date),
         Camera.Deployment.End.Date = as.Date(Camera.Deployment.End.Date)) %>%
  mutate(act.per = as.numeric(difftime(Camera.Deployment.End.Date, 
                                       Camera.Deployment.Begin.Date, units = "days"))) %>%
  group_by(Deployment.Location.ID) %>%
  summarise(act.days = sum(act.per)) %>%
  rename(locationID = Deployment.Location.ID)

stand_mets <- left_join(stand_mets, ct_active_days, by = "locationID") 

#adding PanTheria terrestriality data
traits <- read.csv(file = "data/mammal_list_ct_trait_202405.csv", header = TRUE)
m <- left_join(m, traits[,c("Species","Terrestriality")], by = "Species")

#read terrestrial mammal traits data
terr_traits <- read.csv(file = "data/mammal_traits_terr.csv", header = TRUE)
```

## SPECIES RICHNESS

### Entire Study Area

Excluding arboreal mammals, dogs, and taxa not identified to species level (Muntiacus spp., Tragulus spp. and Unid civets). All camera trap locations: 36 total species.

```{r}
#list of taxa not ID'd to species level, to exclude from some analyses
unid_taxa <- c("Canis familiaris", "Muntiacus spp.", "Tragulus spp.", "Unid civet")

#all camera trap locations
m %>%
  filter(Terrestriality == 1 &
         !Species %in% unid_taxa) %>%
  summarise(SpeciesRichness = n_distinct(Species))
```

Compared to only CT locations that have LiDAR data: 34 total species

```{r}
#only camera trap locations that have LiDAR scan data
m %>%
  filter(locationID %in% stand_mets$locationID & 
           Terrestriality == 1 &
         !Species %in% unid_taxa) %>%
  summarise(SpeciesRichness = n_distinct(Species))
```

### By forest type

Excluding arboreal mammals

```{r}
#all ct locations
n_by_ft <- m %>%
  group_by(habitat) %>%
  filter(Terrestriality == 1 &
         !Species %in% unid_taxa) %>%
  summarise(n.all = n_distinct(Species)) %>%
  arrange(desc(habitat))

#only scanned locations
n_by_ft <- m %>%
  filter(locationID %in% stand_mets$locationID) %>%
  group_by(habitat) %>%
  filter(Terrestriality == 1 &
         !Species %in% unid_taxa) %>%
  summarise(n.scanned = n_distinct(Species)) %>%
  left_join(n_by_ft) %>%
  arrange(desc(habitat))

#the scanned sites consistently observe fewer species over the study period by 4 - 10 species
#more bias in the higher elevation FT's, especially the montane
n_by_ft$diff <- n_by_ft$n.all - n_by_ft$n.scanned
n_by_ft
```

### By partition

Excluding unid animals

```{r}
#all ct locations
n_by_pt <- m %>%
  group_by(partition) %>%
  filter(Terrestriality == 1 &
         !Species %in% unid_taxa) %>%
  summarise(n.all = n_distinct(Species)) %>%
  arrange(desc(partition))

#only scanned locations
n_by_pt <- m %>%
  filter(locationID %in% stand_mets$locationID) %>%
  group_by(partition) %>%
  filter(Terrestriality == 1 &
         !Species %in% unid_taxa) %>%
  summarise(n.scanned = n_distinct(Species)) %>%
  left_join(n_by_pt) %>%
  arrange(desc(partition))

#the scanned sites consistently observe fewer species but this is especially true in UG1 and LS2
n_by_pt$diff <- n_by_pt$n.all - n_by_pt$n.scanned
n_by_pt

```

Again, but for terrestrial mammals only

```{r}
#filtering
m_filtered <- m %>%
  filter(Terrestriality == 1 &
         !Species %in% unid_taxa)

#by all partitions
ct_div_mets_terr <- m_filtered %>%
  group_by(partition) %>%
  summarise(n.terr = n_distinct(Species)) %>%
  arrange(desc(partition))

#by aggregated montane partition - combining MO1 and MO2 into one 'partition"
#ct_div_mets_terr_mod <- m_filtered %>%
 # mutate(partition = case_when(partition %in% c("MO1", "MO2") ~ "MO", TRUE ~ as.character(partition))) %>%
  #group_by(partition) %>%
  #summarise(n.terr = n_distinct(Species)) %>%
  #arrange(desc(partition))
```

### By camera trap location

Excluding arboreal mammals

```{r}
#all CT locations
n_by_ct <- m_filtered %>%
  group_by(locationID) %>%
  summarise(n.all = n_distinct(Species))

#compare 'all CT' and 'scanned CT' location richness distributions
#the 'scanned CT' locations seem biased towards higher species richness
hist(n_by_ct$n.all, breaks = 25,
     main = "species richness - all ct locations", xlab = "n species")
summary(n_by_ct$n.all)

hist(n_by_ct$n.all[n_by_ct$locationID %in% stand_mets$locationID], breaks = 20,
     main = "species richness - scanned ct locations only", xlab = "n species")
summary(n_by_ct$n.all[n_by_ct$locationID %in% stand_mets$locationID])
```

## SHANNON DIVERSITY

### By camera trap location

```{r}
shannon_ct <- diversity(table(m_filtered$locationID, m_filtered$Species), index = "shannon")
shannon_ct <- rownames_to_column(as.data.frame(shannon_ct), var = "locationID")
shannon_ct$locationID <- as.integer(shannon_ct$locationID)

#compare 'all CT' and 'scanned CT' location Shannon Diversity value distributions
#the 'scanned CT' locations seem only slightly biased towards higher diversity values
hist(shannon_ct$shannon_ct, breaks = 25, xlim = c(0,3),
     main = "species diversity - all ct locations", xlab = "Shannon Diversity Index")
summary(shannon_ct$shannon_ct)

hist(shannon_ct$shannon_ct[shannon_ct$locationID %in% stand_mets$locationID], breaks = 25, xlim = c(0,3),
     main = "species diversity - scanned ct locations only", xlab = "Shannon Diversity Index")
summary(shannon_ct$shannon_ct[shannon_ct$locationID %in% stand_mets$locationID])
```

### By partition

Comparing Shannon diversity aggregated at partition for all ct locations to only locations with LiDAR data

```{r}
shannon_all <- diversity(table(m_filtered$partition, m_filtered$Species), index = "shannon")
shannon_all <- rownames_to_column(as.data.frame(shannon_all), var = "partition")

shannon_scan <- diversity(table(m_filtered$partition[shannon_ct$locationID %in% stand_mets$locationID], 
                                m_filtered$Species[shannon_ct$locationID %in% stand_mets$locationID]), 
                          index = "shannon")

shannon_scan <- rownames_to_column(as.data.frame(shannon_scan), var = "partition")
shannon_pt <- left_join(shannon_all, shannon_scan)
rm(shannon_scan, shannon_all)

shannon_pt$diff <- shannon_pt$shannon_all - shannon_pt$shannon_scan
shannon_pt
```

Creating Shannon diversity metrics for terrestrial mammals only, for all partitions and partitions with montane aggregate

```{r}
### All partitions

#calculating Shannon diversity
shan_terr <- as.data.frame(diversity(table(m_filtered$partition, m_filtered$Species)))
colnames(shan_terr)[1] <- "Shannon"
shan_terr <- rownames_to_column(shan_terr, var = "partition")
ct_div_mets_terr <- left_join(ct_div_mets_terr, shan_terr, by = "partition")
rm(shan_terr)

#aggregated montane
#m_filtered_agg <- m_filtered %>%
 # mutate(partition = case_when(partition %in% c("MO1", "MO2") ~ "MO", TRUE ~ as.character(partition)))

#shan_terr <- as.data.frame(diversity(table(m_filtered_agg$partition, m_filtered_agg$Species)))
#colnames(shan_terr)[1] <- "Shannon"
#shan_terr <- rownames_to_column(shan_terr, var = "partition")
#ct_div_mets_terr_mod <- left_join(ct_div_mets_terr_mod, shan_terr, by = "partition")
#rm(shan_terr)
```

### By forest type

```{r}
#calculating shannon diversity index for all and scanned CT locations
shannon_all <- diversity(table(m_filtered$habitat, m_filtered$Species), index = "shannon")
shannon_all <- rownames_to_column(as.data.frame(shannon_all), var = "habitat")

shannon_scan <- diversity(table(m_filtered$habitat[shannon_ct$locationID %in% stand_mets$locationID],
                                m_filtered$Species[shannon_ct$locationID %in% stand_mets$locationID]), 
                          index = "shannon")

shannon_scan <- rownames_to_column(as.data.frame(shannon_scan), var = "habitat")
shannon_ft <- left_join(shannon_all, shannon_scan)
rm(shannon_scan, shannon_all)

#calculating difference between all and scanned locations shannon index
shannon_ft$diff <- shannon_ft$shannon_all - shannon_ft$shannon_scan
shannon_ft
```

## SPECIES EVENNESS

### By camera trap location

Pielou's diversity measure of species evenness

```{r}
div_mets <- shannon_ct %>%
  left_join(., n_by_ct) %>%
  mutate(div_even = shannon_ct/log(n.all))
div_mets$div_even[div_mets$div_even == "NaN"] <- 0

hist(div_mets$div_even, breaks = 25,
     main = "species evenness", xlab = "Pielou's Evenness Index")
```

### By partition

Pielou's diversity measure of species evenness

```{r}
ct_div_mets_terr$evenness <- ct_div_mets_terr$Shannon / log(ct_div_mets_terr$n.terr)

#not running for now since I don't need this modified montane partition 
#ct_div_mets_terr_mod$evenness <- ct_div_mets_terr_mod$Shannon / log(ct_div_mets_terr_mod$n.terr)
```

adding diversity metrics to forest structure metrics df

```{r}
stand_mets <- left_join(stand_mets, div_mets[,c("locationID","n.all","shannon_ct","div_even")], 
                        by = "locationID")
stand_mets$div_even <- as.numeric(stand_mets$div_even)
```


## FUNCTIONAL DIVERSITY METRICS

### By camera trap location

```{r}
#creating observation table
obs_table <- m %>%
  filter(Species %in% terr_traits$Species) %>%
  filter(!Species %in% c("Tragulus spp.","Unid civet","Unid Rat","Muntiacus spp.")) %>%
  group_by(locationID, Species) %>%
  summarise(n.ind = sum(Number.of.Animals)) %>%
  pivot_wider(names_from = Species, values_from = n.ind)
  #left_join(., ct_active_days) %>%
  #mutate(across(-0, ~ . / act.days))

#placing columns in alphabetical order
species_columns <- sort(setdiff(names(obs_table), c("locationID", "act.days")))
obs_table <- obs_table %>% dplyr::select(locationID, all_of(species_columns))
obs_table <- as.data.frame(obs_table)

#setting locations as row names
rownames(obs_table) <- obs_table$locationID
obs_table <- obs_table[,-1]

#adjusting traits table
terr_traits_trim <- terr_traits[!terr_traits$Species %in% 
                                  c("Tragulus spp.","Unid civet",
                                    "Unid Rat","Muntiacus spp."),
                               -c(2,8,9)]

#setting species as row names
rownames(terr_traits_trim) <- terr_traits_trim$Species
terr_traits_trim <- terr_traits_trim[,-1]

#setting categorical vars as factors
terr_traits_trim$ActivityCycle <- as.factor(terr_traits_trim$ActivityCycle)
terr_traits_trim$TrophicLevel <- as.factor(terr_traits_trim$TrophicLevel)

#estimating functional diversity metrics
fd_metrics <- dbFD(terr_traits_trim, obs_table)

#fd metrics not calculated for CT locations with < 3 species (n = 12/172)
#table(is.na(fd_metrics$FRic))

#subset of metrics of interest
fd_metrics_df <- data.frame(
  locationID = as.integer(rownames(as.data.frame(fd_metrics$FRic))), 
  FRich = fd_metrics$FRic, 
  FEven = fd_metrics$FEve, 
  FDiver = fd_metrics$FDiv, 
  stringsAsFactors = FALSE)

#add to metrics table
stand_mets <- left_join(stand_mets, fd_metrics_df, by = "locationID")

#one scanned location is missing FD metric data: TL 26 S40, LG1
#stand_mets[is.na(stand_mets$FRich),]
```


### By partition

```{r}
#creating observation table by partition
obs_table_pt <- m %>%
  filter(Species %in% terr_traits$Species) %>%
  filter(!Species %in% c("Tragulus spp.","Unid civet","Unid Rat","Muntiacus spp.")) %>%
  group_by(partition, Species) %>%
  summarise(n.ind = sum(Number.of.Animals)) %>%
  pivot_wider(names_from = Species, values_from = n.ind)

#adding survey effort (n ct days)
ct_active_days <- left_join(ct_active_days, ct[,c("locationID", "habitat", "partition")])

obs_table_pt <- ct_active_days %>%
  group_by(partition) %>%
  summarise(act.days = sum(act.days)) %>%
  left_join(obs_table_pt, ., by = "partition")

#standardizing by survey effort and assigning partition to row names
#obs_table_pt <- obs_table_pt %>% mutate(across(-0, ~ . / act.days))

obs_table_pt <- as.data.frame(obs_table_pt)
rownames(obs_table_pt) <- obs_table_pt$partition
obs_table_pt <- obs_table_pt[,-c(1, 37)]

#placing column names in alphabetical order
obs_table_pt <- obs_table_pt[, order(names(obs_table_pt))]

#calculating FD mets by partition
fd_metrics_pt <- dbFD(terr_traits_trim, obs_table_pt)

#subset of metrics of interest
fd_metrics_pt_df <- data.frame(
  partition = rownames(as.data.frame(fd_metrics_pt$FRic)), 
  FRich = fd_metrics_pt$FRic, 
  FEven = fd_metrics_pt$FEve, 
  FDiver = fd_metrics_pt$FDiv, 
  stringsAsFactors = FALSE)

#add to metrics table
ct_div_mets_terr <- left_join(ct_div_mets_terr, fd_metrics_pt_df, by = "partition")
```


## COMMUNITY METRICS VISUALIZATION

```{r, include=FALSE}
#add habitat data to diversity metrics table
div_mets <- left_join(div_mets, ct[,c("locationID","habitat","partition","altitude")])
div_mets$habitat <- factor(div_mets$habitat, levels = c("Peat Swamp","Freshwater Swamp","Alluvial Bench",
                                                        "Lowland Sandstone","Lowland Granite",
                                                        "Upland Granite","Montane"))
#copying for visualization use only
div_mets$dataset <- "all"
div_mets$dataset[div_mets$locationID %in% stand_mets$locationID] <- "scanned"

div_mets_viz <- div_mets
div_mets_viz_scan <- div_mets_viz[div_mets_viz$dataset == "scanned",]
div_mets_viz$dataset <- "all"
div_mets_viz <- rbind(div_mets_viz, div_mets_viz_scan)
```

### Community metrics by CT location/forest type

```{r eval=FALSE, fig.height=4, fig.width=10, include=FALSE}
#plotting richness by all and scanned locations in same plot 
cmp1 <- ggplot(div_mets_viz, aes(x = habitat, y = n.all, fill = dataset)) +
  geom_boxplot(position = position_dodge(width = 0.75), width = 0.5) +
  geom_jitter(position = position_dodge(width = 0.75)) +
  scale_fill_manual(values = c("cornflowerblue","coral3")) +
  theme_classic() +
  labs(title = "Species Richness", x = "", y = "n species", fill = "") +
  coord_flip() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

#plotting diversity by all and scanned locations in same plot 
cmp2 <- ggplot(div_mets_viz, aes(x = habitat, y = shannon_ct, fill = dataset)) +
  geom_boxplot(position = position_dodge(width = 0.75), width = 0.5) +
  geom_jitter(position = position_dodge(width = 0.75)) +
  scale_fill_manual(values = c("cornflowerblue","coral3")) +
  theme_classic() +
  labs(title = "Shannon Diversity", x = "", y = "Shannon Diversity Index", fill = "") +
  coord_flip() +
  theme(legend.position = "none", axis.text.y = element_blank(), 
        plot.title = element_text(hjust = 0.5))

#plotting evenness by all and scanned locations in same plot 
cmp3 <- ggplot(div_mets_viz, aes(x = habitat, y = div_even, fill = dataset)) +
  geom_boxplot(position = position_dodge(width = 0.75), width = 0.5) +
  geom_jitter(position = position_dodge(width = 0.75)) +
  scale_fill_manual(values = c("cornflowerblue","coral3")) +
  theme_classic() +
  labs(title = "Species Evenness", x = "", y = "Evenness Index", fill = "") +
  coord_flip() +
  guides(fill = guide_legend(reverse = TRUE), color = guide_legend(reverse = TRUE)) +
  theme(legend.position = "none", axis.text.y = element_blank(), 
        plot.title = element_text(hjust = 0.5))

#cowplot::plot_grid(p1, p2, p3, nrow = 1, rel_widths = c(.4, .3, .3))
```


```{r fig.height=8, fig.width=10}
#add forest type/partition and elevation data to FD mets table
fd_metrics_df <- left_join(fd_metrics_df, ct[,c("locationID","habitat","partition")], by = "locationID")
fd_metrics_df$habitat <- factor(fd_metrics_df$habitat, 
                                levels = c("Peat Swamp","Freshwater Swamp","Alluvial Bench",
                                           "Lowland Sandstone", "Lowland Granite", "Upland Granite",
                                           "Montane"), ordered = TRUE)

fd_metrics_df <- left_join(fd_metrics_df, ct_elev[,c("locationID","altitude")])

ft_colors <- c("Peat Swamp" = "#401D00", 
                      "Freshwater Swamp" = "#643E00", 
                      "Alluvial Bench" = "#896007", 
                      "Lowland Sandstone" = "#AF8228", 
                      "Lowland Granite" = "#D3A43B", 
                      "Upland Granite" = "#F4C444",
                      "Montane" = "#FFDD2D")

cmp1 <- ggplot(div_mets[div_mets$n.all > 0,], aes(x = habitat, y = n.all, color = habitat)) +
  geom_boxplot(width = 0.5, outlier.shape = NA) +
  geom_jitter(width = 0.1, size = 1) +
  theme_classic() +
  labs(title = "", x = "", y = "Richness") +
  coord_flip() +
  theme(legend.position = "none") + 
  scale_color_manual(values = ft_colors)

cmp2 <- ggplot(div_mets[div_mets$shannon_ct > 0,], aes(x = habitat, y = shannon_ct, color = habitat)) +
  geom_boxplot(width = 0.5, outlier.shape = NA) +
  geom_jitter(width = 0.1, size = 1) +
  theme_classic() +
  labs(title = "", x = "", y = "Shannon Diversity") +
  coord_flip() +
  theme(legend.position = "none",
         axis.text.y = element_blank()) + 
  scale_color_manual(values = ft_colors)

cmp3 <- ggplot(div_mets[div_mets$div_even > 0,], aes(x = habitat, y = div_even, color = habitat)) +
  geom_boxplot(width = 0.5, outlier.shape = NA) +
  geom_jitter(width = 0.1, size = 1) +
  theme_classic() +
  labs(title = "", x = "", y = "Evenness") +
  coord_flip() +
  theme(legend.position = "none",
         axis.text.y = element_blank()) + 
  scale_color_manual(values = ft_colors)

fdp1 <- ggplot(fd_metrics_df, aes(x = habitat, y = FRich, color = habitat)) +
  geom_boxplot(width = 0.5, outlier.shape = NA) +
  geom_jitter(width = 0.1, size = 1) +
  theme_classic() +
  labs(title = "", x = "", y = "Func. Rich.") +
  coord_flip() +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "none") + 
  scale_color_manual(values = ft_colors)

fdp2 <- ggplot(fd_metrics_df, aes(x = habitat, y = FEven, color = habitat)) +
  geom_boxplot(width = 0.5, outlier.shape = NA) +
  geom_jitter(width = 0.1, size = 1) +
  theme_classic() +
  labs(title = "", x = "", y = "Func. Even.") +
  coord_flip() +
  theme(axis.text.y = element_blank(),
        legend.position = "none") + 
  scale_color_manual(values = ft_colors)

fdp3 <- ggplot(fd_metrics_df, aes(x = habitat, y = FDiver, color = habitat)) +
  geom_boxplot(width = 0.5, outlier.shape = NA) +
  geom_jitter(width = 0.1, size = 1) +
  theme_classic() +
  labs(title = "", x = "", y = "Func. Diver.") +
  coord_flip() +
  theme(axis.text.y = element_blank(),
        legend.position = "none") + 
  scale_color_manual(values = ft_colors)

cowplot::plot_grid(cmp1, cmp2, cmp3, fdp1, fdp3, fdp2, nrow = 2, rel_widths = c(.4, .3, .3))
```

### Community metrics by elevation

```{r fig.height=4, fig.width=10}
#species richness by elevation - 'all CT locations' and "scanned locations' in the same plot
p1 <- ggplot(div_mets, aes(x = altitude, y = n.all)) +
  geom_point() +
  geom_smooth() +  
  theme_classic() +
  theme(legend.position = "none") + 
  labs(title = "", x = "", y = "Richness (n species)")

#shannon diversity by elevation
p2 <- ggplot(div_mets[div_mets$shannon_ct > 0,], aes(x = altitude, y = shannon_ct)) +
  geom_point() +
  geom_smooth() +  
  theme_classic() +
  theme(legend.position = "none") + 
  labs(title = "", x = "", y = "Shannon Diversity Index")

#species evenness by elevation
p3 <- ggplot(div_mets[div_mets$div_even > 0,], aes(x = altitude, y = div_even)) +
  geom_point() +
  geom_smooth() +  
  theme_classic() +
  theme(legend.position = "none") + 
  labs(title = "", x = "", y = "Evenness Index")

#functional richness
p4 <- ggplot(fd_metrics_df, aes(x = altitude, y = FRich)) +
  geom_point() +
  geom_smooth() +  
  theme_classic() +
  theme(legend.position = "none",) + 
  labs(title = "", x = "", y = "Func. Rich.")

p5 <- ggplot(fd_metrics_df, aes(x = altitude, y = FEven)) +
  geom_point() +
  geom_smooth() +  
  theme_classic() +
  theme(legend.position = "none") + 
  labs(title = "", x = "", y = "Func. Even.")

p6 <- ggplot(fd_metrics_df, aes(x = altitude, y = FDiver)) +
  geom_point() +
  geom_smooth() +  
  theme_classic() +
  theme(legend.position = "none") + 
  labs(title = "", x = "elevation (m)", y = "Func. Diver.")

cowplot::plot_grid(p1,p2,p3,p4,p6,p5, nrow = 2)
```


## DISTANCE x DISSIMILARITY

Calculating pairwise distance for scanned locations and plotting values by pairwise similarity, with blue points showing pairs in the same forest type and red points pairs in different partitions. I include community metrics here as well, but it might be worthwhile to see what the linear models look like for these for the full set of camera traps, since we know that the community metrics for only the scanned sites differs from the values for all CT sites, especially in the higher elevation partitions.
```{r fig.height=8, fig.width=10}
#pairwise distances for scanned locations
distance_df <- as.data.frame(as.table(distm(stand_mets[,c("longitude","latitude")], fun = distHaversine)))
colnames(distance_df) <- c("loc1", "loc2", "distance")
distance_df$loc1 <- as.integer(distance_df$loc1)
distance_df$loc2 <- as.integer(distance_df$loc2)

#pairwise similarity for each metric
metric_list <- c("max.height", "sd.r", "CRR.rho", "pts.below.2m", "stand.dens", "basal.area", 
             "stem.vol", "mean.tree.h", "mean.dbh", "zentropy", "lad.max", "rumple", 
             "vFRcanopy", "vzrumple", "ClosedGapSpace","n.all", "shannon_ct", "div_even")

similarity_list <- lapply(metric_list, function(metric) {
  metric_data <- stand_mets[[metric]]
  similarity_matrix <- as.matrix(dist(metric_data))
  similarity_df <- as.data.frame(as.table(similarity_matrix))
  colnames(similarity_df) <- c("loc1", "loc2", "similarity")
  similarity_df$metric <- metric
  return(similarity_df)
})

similarity_df <- do.call(rbind, similarity_list)
similarity_df$loc1 <- as.integer(similarity_df$loc1)
similarity_df$loc2 <- as.integer(similarity_df$loc2)

#combine distance and similarity data
pairs_df <- distance_df %>%
  left_join(similarity_df, by = c("loc1", "loc2")) %>%
  mutate(
    same_pt = stand_mets$partition[as.integer(loc1)] == stand_mets$partition[as.integer(loc2)],
    same_pt = ifelse(same_pt, "same", "different"))

#plot
ggplot(pairs_df[!pairs_df$distance == 0,], 
       aes(x = distance, y = similarity)) +
  geom_point(aes(color = same_pt, shape = same_pt), 
             alpha = 0.5, size = 0.75) +
  geom_smooth(aes(group = same_pt, color = same_pt), 
              method = "lm", se = FALSE) +
  facet_wrap(~ metric, scales = "free_y") +
  labs(x = "Geographic Distance (m)", y = "Structural Dissimilarity (Euclidean Distance)",
       color = "partition", shape = "partition") +
  scale_color_manual(values = c("same" = "blue", "different" = "red")) +
  theme_minimal() +
  theme(legend.position = c(0.8, 0.02),
        legend.justification = c(1, 0),   
        legend.box.just = "right")
```


Comparison table showing intercepts and slopes of the linear models plotted above. 11/15 structure metrics show a lower intercept for the 'same partition' group compared to the 'different partition' group, while 9/15 show lower slope values for the 'same partition' group. 'inst.s.lt.d' = intercept 'same' less than 'different'. 'slo.s.lt.d' = slope 'same' less than 'different'
```{r}
#list for intercepts and slopes
model_results <- lapply(metric_list, function(metric_name) {
  metric_df <- pairs_df %>%
    filter(metric == metric_name & distance != 0)

  model_same <- lm(similarity ~ distance, data = metric_df[metric_df$same_pt == "same",])
  model_different <- lm(similarity ~ distance, data = metric_df[metric_df$same_pt == "different",])

  intercept_same <- coef(model_same)[1]
  slope_same <- coef(model_same)[2]
  
  intercept_different <- coef(model_different)[1]
  slope_different <- coef(model_different)[2]
  
  intercept_comparison <- intercept_same < intercept_different
  slope_comparison <- slope_same < slope_different
  
  data.frame(
    metric = metric_name,
    int.same = intercept_same,
    int.diff = intercept_different,
    slope.same = slope_same,
    slope.diff = slope_different,
    int.s.lt.d = intercept_comparison,
    slo.s.lt.d = slope_comparison
  )
})

#combine into one table
(model_results <- do.call(rbind, model_results))
```

again for the 170 ha grid for comparison. 8/15 metrics show an intercept lower for within-cell pairs compared to between cells 
```{r eval=FALSE, include=FALSE}
#combine distance and similarity data
pairs_df <- distance_df %>%
  left_join(similarity_df, by = c("loc1", "loc2")) %>%
  mutate(
    same_pt = stand_mets$grid170[as.integer(loc1)] == stand_mets$grid170[as.integer(loc2)],
    same_pt = ifelse(same_pt, "same", "different"))

#list for intercepts and slopes
model_results2 <- lapply(metric_list, function(metric_name) {
  metric_df <- pairs_df %>%
    filter(metric == metric_name & distance != 0)

  model_same <- lm(similarity ~ distance, data = metric_df[metric_df$same_pt == "same",])
  model_different <- lm(similarity ~ distance, data = metric_df[metric_df$same_pt == "different",])

  intercept_same <- coef(model_same)[1]
  slope_same <- coef(model_same)[2]
  
  intercept_different <- coef(model_different)[1]
  slope_different <- coef(model_different)[2]
  
  intercept_comparison <- intercept_same < intercept_different
  slope_comparison <- slope_same < slope_different
  
  data.frame(
    metric = metric_name,
    int.same = intercept_same,
    int.diff = intercept_different,
    slope.same = slope_same,
    slope.diff = slope_different,
    int.s.lt.d = intercept_comparison,
    slo.s.lt.d = slope_comparison
  )
})

#combine into one table
(model_results2 <- do.call(rbind, model_results2))
```


## SPATIAL AUTOCORRELATION

First I want to just visualize spatial patterns of structure variables and community metrics across the study site, by camera trap location. 
```{r fig.height=8, fig.width=10}
stand_mets %>%
  dplyr::select(locationID, longitude, latitude, metric_list, FRich, FEven, FDiver) %>%
  tidyr::pivot_longer(cols = -c(locationID, longitude, latitude), 
                      names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  mutate(norm_value = (value - min(value, na.rm = TRUE)) / (max(value, na.rm = TRUE) - min(value, na.rm = TRUE))) %>%
  ungroup() %>%
  ggplot(aes(x = longitude, y = latitude, color = norm_value)) +
  geom_point(size = 3) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0.5) +
  facet_wrap(~ variable, scales = "free") +
  labs(x = "longitude", y = "latitude", color = "Metric Value (normalized") +
  theme_minimal() +
  theme(strip.background = element_blank(),
        strip.text = element_text(size = 10),
        legend.position = c(1, 0),
        legend.justification = c(1, 0),
        legend.key.size = unit(0.3, "cm"),
        legend.text = element_text(size = 8))
```


Mapping the community metrics by all CT locations (the figure above only plots scanned locations)
```{r}
# Specify the order of the variables and rename them
div_mets_viz %>%
  dplyr::select(locationID, shannon_ct, n.all, div_even) %>%
  left_join(fd_metrics_df, by = "locationID") %>%
  left_join(ct[, c("locationID", "latitude", "longitude")]) %>%
  tidyr::pivot_longer(cols = c(n.all, shannon_ct, div_even, FRich, FEven, FDiver), 
                      names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  mutate(norm_value = (value - min(value, na.rm = TRUE)) / (max(value, na.rm = TRUE) - min(value, na.rm = TRUE))) %>%
  ungroup() %>%
  mutate(variable = factor(variable, levels = c("n.all", "shannon_ct", "div_even", "FRich", "FEven", "FDiver"),
                           labels = c("Species Richness", "Shannon Diversity", "Species Evenness", 
                                      "Func. Richness", "Func. Evenness", "Func. Divergence"))) %>%
  ggplot(aes(x = longitude, y = latitude, color = norm_value)) +
  geom_point(size = 3) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0.5) +
  facet_wrap(~ variable, scales = "free", labeller = label_value) +
  labs(x = "Longitude", y = "Latitude", color = "") +
  theme_minimal() +
  theme(strip.background = element_blank(),
        strip.text = element_text(size = 10),
        legend.key.size = unit(0.3, "cm"),
        legend.text = element_text(size = 8))

```


### Global Moran's I 

A formal test of spatial autocorrelation across the entire study area. I may only be able to meaningfully test for spatial autocorrelation at this scale, and not at the grid or partition scales, as the typical low end of spatial units required for reliable statistical inference is 30.

Five structure metrics show a significant level of spatial autocorrelation, including max height, vertical rumple, vegetation volume, leaf area density, and mean tree height. 

Looking at the spatial patterns for these metrics in the plots above, max height, vrumple, lad, and mean height seem to show a roughly similar pattern, with low values in the swamp forests and montane, and highest values in the lowland forests in the center of the trail system - exactly what we see in the boxplots of these values plotted by forest type. Vegetation volume (vFRcanopy) shows a different spatial pattern. And rumple, along with closedgapspace show an outlier in the center of the trail system - location BC 12.4 (not sure what's going on with that one)
```{r}
#convert stand mets df to spatial object
stand_mets_sp <- stand_mets
coordinates(stand_mets_sp) <- ~longitude + latitude
proj4string(stand_mets_sp) <- CRS("+proj=longlat +datum=WGS84")

#calculate spatial weights
coords <- coordinates(stand_mets_sp)
distances <- spDists(coords, longlat = TRUE)
max_distance <- max(distances)
threshold <- max_distance * 0.001

#define neighbors based on threshold distance
neighbors <- dnearneigh(coords, 0, threshold)

#binary weights for neighbors
weights <- nb2listw(neighbors, style = "W")

#function to calculate Moran's I and Geary's C
calculate_morans_i <- function(variable, weights) {
  moran_test <- moran.test(variable, weights)
  list(Moran_I = moran_test$estimate[1],
       Expected_I = moran_test$estimate[2],
       Variance = moran_test$estimate[3],
       Z_score = moran_test$statistic,
       P_value = moran_test$p.value)
}

#calculate metrics
spac_mets <- map_dfr(metric_list, function(col) {
  metrics <- calculate_morans_i(stand_mets_sp[[col]], weights)
  tibble(Metric = col,
         Moran_I = metrics$Moran_I,
         Expected_I = metrics$Expected_I,
         Variance_I = metrics$Variance,
         Z_score = metrics$Z_score,
         P_value = metrics$P_value,
         Significant = metrics$P_value < 0.05)
})

#again for functional metrics because there's one less observation point, have to run separately
f_metrics_list <- c("FRich", "FEven", "FDiver")
stand_mets_func <- stand_mets[complete.cases(stand_mets[, c("FRich", "FEven", "FDiver")]),
                              c("FRich", "FEven", "FDiver", "longitude", "latitude")]
coordinates(stand_mets_func) <- ~longitude + latitude
proj4string(stand_mets_func) <- CRS("+proj=longlat +datum=WGS84")

coords <- coordinates(stand_mets_func)
distances <- spDists(coords, longlat = TRUE)
max_distance <- max(distances)
threshold <- max_distance * 0.001
neighbors <- dnearneigh(coords, 0, threshold)
weights_pt <- nb2listw(neighbors, style = "W")

spac_mets2 <- map_dfr(f_metrics_list, function(col) {
  metrics <- calculate_morans_i(stand_mets_func[[col]], weights_pt)
  tibble(Metric = col,
         Moran_I = metrics$Moran_I,
         Expected_I = metrics$Expected_I,
         Variance_I = metrics$Variance,
         Z_score = metrics$Z_score,
         P_value = metrics$P_value,
         Significant = metrics$P_value < 0.05)
})

spac_mets %>%
  rbind(spac_mets2) %>%
  arrange(P_value) %>%
  print(n = Inf)
```


Extracting Moran's eigenvector values to use in glm to control for spatial autocorrelation
```{r}
#convert data to sf object
data_sf <- st_as_sf(stand_mets, coords = c("longitude", "latitude"), crs = 4326)
coords <- st_coordinates(data_sf)

#extract Moran's eigenvectors
mev <- meigen(coords, model = "exp", threshold = 0)
eigenvectors <- mev$ev_full
hist(eigenvectors, breaks = 25)

stand_mets <- cbind(stand_mets, eigenvectors)
```



## CREATING SURVEY GRIDS
```{r include=FALSE}
#convert data to sf object
data_sf <- st_as_sf(stand_mets, coords = c("longitude", "latitude"), crs = 4326)

# Define a function to create a grid and count locations
count_grid_cells <- function(grid_size) {
  grid <- st_make_grid(data_sf, cellsize = grid_size, what = "polygons")
  grid_sf <- st_sf(grid_id = seq_along(grid), geometry = grid)
  counts <- st_intersects(grid_sf, data_sf)
  grid_sf$count <- sapply(counts, length)
  list(grid_sf = grid_sf, num_cells = sum(grid_sf$count > 0), grid_size = grid_size)
}

#function to find grid size
find_grid_size <- function(initial_size, min_cells) {
  size <- initial_size
  result <- count_grid_cells(size)
  
  while (result$num_cells < min_cells) {
    size <- size / 2
    result <- count_grid_cells(size)
  }
  
  result
}
```

Run grid size functions
```{r include=FALSE}
#for medium sized grid (~75 ha)
initial_size <- 1 
min_cells <- 15

#find appropriate grid size
result <- find_grid_size(initial_size, min_cells)
final_grid <- result$grid_sf
num_cells <- result$num_cells
as.numeric(st_area(final_grid)[1]) #in m^2

#plot grid
plot(st_geometry(final_grid), col = "white", border = "grey50", main = "Grid with Survey Locations")
plot(st_geometry(data_sf), add = TRUE, col = "grey30", pch = 16)

#how many scanned locations in each grid cell
grid75 <- st_join(data_sf, final_grid, join = st_within)
table(grid75$grid_id)
length(unique(grid75$grid_id))

#add grid designations to stand mets df
stand_mets <- grid75 %>%
  st_drop_geometry() %>%
  dplyr::select(locationID, grid_id) %>%
  rename(grid75 = grid_id) %>%
  left_join(stand_mets, .)

#adding grid to full CT list and then to mammal obs table (m)
ct_sf <- st_as_sf(ct, coords = c("longitude", "latitude"), crs = 4326)
grid75_cells <- st_join(ct_sf, final_grid, join = st_within)

m_filtered <- grid75_cells %>%
  st_drop_geometry() %>%
  dplyr::select(locationID, grid_id) %>%
  rename(grid.75 = grid_id) %>%
  left_join(m_filtered, .)

#write grid as shapefile
#st_write(final_grid, "medium_grid_75ha.shp")

###########################################################################################################
#for large sized grid (~170 ha)
initial_size <- 48 
min_cells <- 10

#find appropriate grid size
result <- find_grid_size(initial_size, min_cells)
final_grid <- result$grid_sf
num_cells <- result$num_cells
as.numeric(st_area(final_grid)[1]) #in m^2

#plot grid
plot(st_geometry(final_grid), col = "white", border = "grey50", main = "Grid with Survey Locations")
plot(st_geometry(data_sf), add = TRUE, col = "grey30", pch = 16)

#how many scanned locations in each grid cell
grid170 <- st_join(data_sf, final_grid, join = st_within)
table(grid170$grid_id)
length(unique(grid170$grid_id))

#add grid designations to stand mets df
stand_mets <- grid170 %>%
  st_drop_geometry() %>%
  dplyr::select(locationID, grid_id) %>%
  rename(grid170 = grid_id) %>%
  left_join(stand_mets, .)

#adding grid to full CT list and then to mammal obs table (m)
grid170_cells <- st_join(ct_sf, final_grid, join = st_within)

m_filtered <- grid170_cells %>%
  st_drop_geometry() %>%
  dplyr::select(locationID, grid_id) %>%
  rename(grid.170 = grid_id) %>%
  left_join(m_filtered, .)

#write grid as shapefile
#st_write(final_grid, "medium_grid_170ha.shp")
```

Again for the grid that I created in ArcGIS - 650 ha 2X2 
```{r}
grid650 <- read.csv(file = "data/locationID_grid650.csv", header = TRUE)

stand_mets <- grid650 %>%
  dplyr::select(locationID, X650ha_gridID) %>%
  rename(grid650 = X650ha_gridID) %>%
  left_join(stand_mets, .)
```


## MODELING - Terrestrial mammals (CT data)

```{r}
#scale and center numeric predictors
stand_mets <- stand_mets %>% 
  mutate(across(c(5:16, 22:25, 27:29, 37), scale, .names = "{.col}.sc"))
```

#### Descriptions of forest structure metrics used in models

I used {FORTLS} to extract the following metrics:

1.  max.height - maximum height of trees in the stand, in m

2.  mean.tree.h - mean tree height in the stand, in m.

3.  CRR.rho - canopy relief ratio, using rho for horizontal distance. A measure of canopy variation, with lower scores indicating lower local variation in canopy surface, i.e., more uniform age canopy/ less canopy surface complexity.

4.  sd.r - standard deviation of tree heights in stand in m. I've seen this value used as an approximation for vertical stratification.

5.  mean.dbh - mean diameter at breast height of trees in stand, in cm (measured at height of 1.3m)

6.  basal.area - basal area of trees in the stand (m2/ha)

7.  stand.dens - density of trees in the stand (trees/ha)

8.  stem.vol - volume of trees in the stand (m3/ha)

9.  pts.below.2m - shows the number of points in the point cloud that are below 2m.

I used {lidr} and {lidRmetrics} to extract the following metrics:

10. zentropy - normalized Shannon diversity index of z (height) values. Describes vertical complexity.

11. lad.max - Leaf Area Density maximum value for 1m vertical bins. Describes maximum foliage cover of the point cloud.

12. rumple - Rumple index (rugosity), a ratio of the canopy surface area to it's projected ground area.

vn - number of 1m voxels created for the following volumetric metrics.

13. vFRcanopy - ratio of filled to empty voxels, only counting cells within and below canopy, ignoring above.

14. vzrumple - vertical Rumple index.

15. ClosedGapSpace - volume of voxels that are classified as gaps underneath the canopy

#### Check correlation between community metrics and predictors.

PREDICTORS: Basal area is highly correlated (\>0.8) with stem volume and stand density.

```{r}
chart.Correlation(stand_mets[,c("max.height.sc","sd.r.sc","CRR.rho.sc","pts.below.2m.sc","stand.dens.sc",
                                "basal.area.sc","stem.vol.sc","mean.tree.h.sc","mean.dbh.sc", "zentropy.sc",
                                "lad.max.sc","rumple.sc","vFRcanopy.sc","vzrumple.sc","ClosedGapSpace.sc")],
                  method = "spearman")
```

COMMUNITY METS: By camera trap location - species richness & shannon, and FRich and shannon are moderately correlated (both 0.69), FRich and richness are highly correlated (0.82)
```{r}
chart.Correlation(stand_mets[,c("n.all", "shannon_ct", "div_even", "FRich", "FEven", "FDiver")],
                  method = "spearman")
```


### Models by camera trap location
Fitting global model then using {dredge} to find models of best fit.
Restricting models to five predictors to avoid overfitting. Excluding two highly correlated pairs in dredge models: basal area & stand density, and basal area & stem volume.

#### Species richness model

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
rm1 <- glm(n.all ~  
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             eigenvectors.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = stand_mets)
#dredge
rich_models <- dredge(rm1, m.max = 3, 
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc),
                      fixed = "eigenvectors.sc")

#selecting top model by AIC
#top_rich_model <- get.models(rich_models, subset = 1)
#summary(top_rich_model[[1]])
```

averaged model output - averaging all models

```{r}
#averaging models
rich_models_avg <- model.avg(rich_models)
#summary(rich_models_avg)

dev.off()
plot(rich_models_avg, full = FALSE, intercept = FALSE, main = "Terrestrial Mammal Richness - Averaged Model")
```

#### Shannon diversity model

```{r message=FALSE, warning=FALSE}
#species diversity as outcome variable - by CT location
shannon_model <- glm(shannon_ct ~ 
                         max.height.sc +
                         mean.tree.h.sc +
                         CRR.rho.sc +
                         sd.r.sc +
                         mean.dbh.sc +
                         basal.area.sc +
                         stand.dens.sc +
                         stem.vol.sc +
                         pts.below.2m.sc +
                         zentropy.sc +
                         lad.max.sc +
                         rumple.sc +
                         vFRcanopy.sc +
                         vzrumple.sc +
                         eigenvectors.sc +
                         ClosedGapSpace.sc,
                        na.action = na.fail,
                        family = Gamma(link = "log"), 
                        offset = log(act.days),
                        data = stand_mets)
#dredge
shan_models <- dredge(shannon_model, m.max = 3, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc),
                      fixed = "eigenvectors.sc")

#R-squared information
summary(shan_models$`adjR^2`)
#summary(shan_models$`adjR^2`[shan_models$delta < 2])

#selecting top model by AIC
#top_shan_model <- get.models(shan_models, subset = 1)
#summary(top_shan_model[[1]])
```

averaged model output - averaging all models

```{r}
#averaging models
shan_models_avg <- model.avg(shan_models)
summary(shan_models_avg)

plot(shan_models_avg, full = FALSE, intercept = FALSE, main = "Terrestrial Mammal Diversity - Averaged Model")
```

#### Species evenness model

```{r message=FALSE, warning=FALSE, include=FALSE}
even_model <- glm(div_even ~ 
                max.height.sc +
                mean.tree.h.sc +
                CRR.rho.sc +
                sd.r.sc +
                mean.dbh.sc +
                basal.area.sc +
                stand.dens.sc +
                stem.vol.sc +
                pts.below.2m.sc +
                zentropy.sc +
                lad.max.sc +
                rumple.sc +
                vFRcanopy.sc +
                vzrumple.sc +
                eigenvectors.sc +
                ClosedGapSpace.sc,
                na.action = na.fail,
              family = Gamma(link = "log"), 
              offset = log(act.days),
              data = stand_mets)
#dredge
even_models <- dredge(even_model, m.max = 3, 
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc),
                      fixed = "eigenvectors.sc")

#selecting top model by AIC
#top_even_model <- get.models(even_models, subset = 1)
#summary(top_even_model[[1]])
```

averaged model output - averaging all models

```{r}
#averaging all models
even_models_avg <- model.avg(even_models)
#summary(even_models_avg)

plot(even_models_avg, full = FALSE, intercept = FALSE, main = "Terrestrial Mammal Evenness - Avg. Model")
```

#### Functional richness model

Top model summary output

```{r message=FALSE, warning=FALSE, include=FALSE}
stand_mets_FD <- stand_mets[!is.na(stand_mets$FRich),]

frich_model <- glm(FRich ~ 
                max.height.sc +
                mean.tree.h.sc +
                CRR.rho.sc +
                sd.r.sc +
                mean.dbh.sc +
                basal.area.sc +
                stand.dens.sc +
                stem.vol.sc +
                pts.below.2m.sc +
                zentropy.sc +
                lad.max.sc +
                rumple.sc +
                vFRcanopy.sc +
                vzrumple.sc +
                #eigenvectors.sc +
                ClosedGapSpace.sc,
                na.action = na.fail,
              family = Gamma(link = "log"), 
              offset = log(act.days),      
              data = stand_mets_FD)
#dredge
frich_models <- dredge(frich_model, m.max = 2, 
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc))

#selecting top model by AIC
#top_frich_model <- get.models(frich_models, subset = 1)
#summary(top_frich_model[[1]])
```

averaged model output - averaging all models

```{r}
frich_models_avg <- model.avg(frich_models)
#summary(frich_models_avg)

plot(frich_models_avg, full = FALSE, intercept = FALSE, main = "Functional Richness - Avg. Model")
```

#### Functional evenness model

Top model summary output

```{r message=FALSE, warning=FALSE, include=FALSE}
feven_model <- glm(FEven ~ 
                max.height.sc +
                mean.tree.h.sc +
                CRR.rho.sc +
                sd.r.sc +
                mean.dbh.sc +
                basal.area.sc +
                stand.dens.sc +
                stem.vol.sc +
                pts.below.2m.sc +
                zentropy.sc +
                lad.max.sc +
                rumple.sc +
                vFRcanopy.sc +
                vzrumple.sc +
                ClosedGapSpace.sc,
                na.action = na.fail,
              family = Gamma(link = "log"), 
              offset = log(act.days),
              data = stand_mets_FD)
#dredge
feven_models <- dredge(feven_model, m.max = 2, 
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc))

#selecting top model by AIC
#top_feven_model <- get.models(feven_models, subset = 1)
#summary(top_feven_model[[1]])
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
feven_models_avg <- model.avg(feven_models)
summary(feven_models_avg)
```

```{r}
plot(feven_models_avg, full = FALSE, intercept = FALSE, main = "Functional Evenness - Avg. Model")
```


#### Functional divergence model

Top model summary output

```{r message=FALSE, warning=FALSE, include=FALSE}
fdiver_model <- glm(FDiver ~ 
                max.height.sc +
                mean.tree.h.sc +
                CRR.rho.sc +
                sd.r.sc +
                mean.dbh.sc +
                basal.area.sc +
                stand.dens.sc +
                stem.vol.sc +
                pts.below.2m.sc +
                zentropy.sc +
                lad.max.sc +
                rumple.sc +
                vFRcanopy.sc +
                vzrumple.sc +
                eigenvectors.sc +
                ClosedGapSpace.sc,
                na.action = na.fail,
              family = Gamma(link = "log"), 
              offset = log(act.days),
              data = stand_mets_FD)
#dredge
fdiver_models <- dredge(fdiver_model, m.max = 3, 
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc),
                      fixed = "eigenvectors.sc")

#selecting top model by AIC
#top_fdiver_model <- get.models(fdiver_models, subset = 1)
#summary(top_fdiver_model[[1]])
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
fdiver_models_avg <- model.avg(fdiver_models)
summary(fdiver_models_avg)
```

```{r}
plot(fdiver_models_avg, full = FALSE, intercept = FALSE, main = "Functional Divergence - Avg. Model")
```


#### Comparing coefficient plot from averaged models

Plotting variables from models that are at least closely reliable predictors (50% CI's don't overlap zero).

```{r fig.height=5, fig.width=6}
#function to extract coefficients and confidence intervals
extract_coefs <- function(model_avg, model_name) {
  coefs <- as.data.frame(confint(model_avg))
  coefs$predictor <- rownames(coefs)
  coefs$estimate <- coef(model_avg)
  coefs$model <- model_name
  confint50 <- confint(model_avg, level = 0.5)
  coefs$`25 %` <- confint50[, 1]
  coefs$`75 %` <- confint50[, 2]
  return(coefs)
}

#extract coefficients from averaged models
coef_rich <- extract_coefs(rich_models_avg, "rich")
coef_shan <- extract_coefs(shan_models_avg, "shan")
coef_even <- extract_coefs(even_models_avg, "even")
coef_fric <- extract_coefs(frich_models_avg, "fric")
coef_feve <- extract_coefs(feven_models_avg, "feve")
coef_fdiv <- extract_coefs(fdiver_models_avg, "fdiv")

#combine all
coef_df <- rbind(coef_rich, coef_shan, coef_even, coef_fric, coef_feve, coef_fdiv)
rm(coef_rich, coef_shan, coef_even, coef_fric, coef_feve, coef_fdiv)

#specifying order to plot models
coef_df$model <- factor(coef_df$model, levels = rev(c("rich","shan","even","fric","feve","fdiv")))

#select only predictors with 50% CI's that don't overlap zero
coef_df_filter <- coef_df[!(coef_df$`25 %` <= 0 & coef_df$`75 %` >= 0),]
coef_df_filter <- coef_df_filter[!coef_df_filter$predictor %in% c("(Intercept)", "eigenvectors.sc"),]

#plotting - only the functional models for now
coef_df_filter %>%
  filter(model %in% c("shan")) %>%
ggplot(aes(x = estimate, y = predictor, color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(title = "Reliable Predictors from Averaged CT Models",
       x = "Coefficient Estimate", y = "") +
  theme(axis.text.y = element_text(hjust = 1),
        legend.position = "bottom") +
  guides(color = guide_legend(reverse = TRUE))
```


### MODELS BY GRID

#### 75 ha grid

The 75 ha grid creates 17 groups, with most groups (grid cells) containing 2 - 4 scanned locations each. 
```{r include=FALSE}
#species richness
#all CT locations
grid75_mets <- m_filtered %>%
  group_by(grid.75) %>%
  summarise(n.all = n_distinct(Species))

#shannon diversity
shannon_75 <- diversity(table(m_filtered$grid.75, m_filtered$Species), index = "shannon")
shannon_75 <- rownames_to_column(as.data.frame(shannon_75), var = "grid.75")
shannon_75$grid.75 <- as.integer(shannon_75$grid.75)

#species evenness
grid75_mets <- shannon_75 %>%
  left_join(., grid75_mets) %>%
  mutate(even.75 = shannon_75/log(n.all))

### functional metrics ###
#creating observation table by partition
obs_table_75 <- m_filtered %>%
  filter(Species %in% terr_traits$Species) %>%
  filter(!Species %in% c("Tragulus spp.","Unid civet","Unid Rat","Muntiacus spp.")) %>%
  group_by(grid.75, Species) %>%
  summarise(n.ind = sum(Number.of.Animals)) %>%
  pivot_wider(names_from = Species, values_from = n.ind)

#adding survey effort
ct_active_days <- grid75_cells %>%
  st_drop_geometry() %>%
  rename(grid.75 = grid_id) %>%
  dplyr::select(c(locationID, grid.75)) %>%
  left_join(ct_active_days, .)

obs_table_75 <- ct_active_days %>%
  group_by(grid.75) %>%
  summarise(act.days = sum(act.days)) %>%
  left_join(obs_table_75, ., by = "grid.75")

grid75_mets <- left_join(grid75_mets, obs_table_75[,c("grid.75", "act.days")])

#standardizing by survey effort and assigning partition to row names
#obs_table_75 <- obs_table_75 %>% mutate(across(-0, ~ . / act.days))

obs_table_75 <- as.data.frame(obs_table_75)
obs_table_75 <- obs_table_75[-22,]
rownames(obs_table_75) <- obs_table_75$grid.75
obs_table_75 <- obs_table_75[,-c(1, 37)]

#placing column names in alphabetical order
obs_table_75 <- obs_table_75[, order(names(obs_table_75))]

#calculating FD mets by partition
fd_metrics_75 <- dbFD(terr_traits_trim, obs_table_75)

#subset of metrics of interest
fd_metrics_75_df <- data.frame(
  grid.75 = as.numeric(rownames(as.data.frame(fd_metrics_75$FRic))), 
  FRich = fd_metrics_75$FRic, 
  FEven = fd_metrics_75$FEve, 
  FDiver = fd_metrics_75$FDiv, 
  stringsAsFactors = FALSE)

#add to metrics table
grid75_mets <- left_join(grid75_mets, fd_metrics_75_df, by = "grid.75")

#### calculating mean of all scaled predictors by grid cell
grid75_mets <- stand_mets %>%
  group_by(grid75) %>%
  dplyr::select(ends_with(".sc")) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE)) %>%
  rename(grid.75 = grid75) %>%
  dplyr::select(-eigenvectors.sc) %>%
  left_join(grid75_mets, .)
```

Correlation of community metrics. Richness is highly correlated with FRich and FDiver, and shannon is highly correlated with evenness. So probably should only keep shannon and the functional metrics. 
```{r}
chart.Correlation(grid75_mets[,c("n.all", "shannon_75", "even.75", "FRich", "FEven", "FDiver")],
                  method = "spearman")
```

Correlation of structure metrics - basal area and stand dens, basal area and stem vol, %<2m and sd.r, max h and mean h, max h and vrumple, and mean h and vrumple
```{r}
chart.Correlation(grid75_mets[,c("max.height.sc","sd.r.sc","CRR.rho.sc","pts.below.2m.sc",
                                    "stand.dens.sc","basal.area.sc","stem.vol.sc","mean.tree.h.sc",
                                    "mean.dbh.sc", "zentropy.sc","lad.max.sc","rumple.sc","vFRcanopy.sc",
                                    "vzrumple.sc","ClosedGapSpace.sc")],
                  method = "spearman")
```

#### Species richness model

Fitting global model then using {dredge} to find models of best fit.

Top model summary output. Restricting models to two predictors to avoid overfitting

```{r message=FALSE, warning=FALSE, include=FALSE}
#removing MO1 partition since no structure mets are from this pt
grid75_mets <- grid75_mets[complete.cases(grid75_mets),]

#fitting global model for use in dredge
rm_75 <- glm(n.all ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid75_mets)

#dredge
rich_75_models <- dredge(rm_75, m.max = 2, 
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc))
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
rich_models_75_avg <- model.avg(rich_75_models)
summary(rich_models_75_avg)
```

```{r}
plot(rich_models_75_avg, full = FALSE, intercept = FALSE, main = "Mammal Richness (75 ha grid) - Av. Mod")
```

#### Species diversity model

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
sm_75 <- glm(shannon_75 ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid75_mets)

#dredge
shan_75_models <- dredge(sm_75, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc))

#R-squared information
summary(shan_75_models$`adjR^2`)
#summary(shan_75_models$`adjR^2`[shan_75_models$delta < 2])
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
shan_models_75_avg <- model.avg(shan_75_models)
summary(shan_models_75_avg)
```

```{r}
plot(shan_models_75_avg, full = FALSE, intercept = FALSE, main = "Mammal Diversity (75 ha grid) - Av. Mod")
```

#### Species eveness model

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
em_75 <- glm(even.75 ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid75_mets)

#dredge
even_75_models <- dredge(em_75, m.max = 2, 
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc))
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
even_models_75_avg <- model.avg(even_75_models)
summary(even_models_75_avg)
```

```{r}
plot(even_models_75_avg, full = FALSE, intercept = FALSE, main = "Mammal Evenness (75 ha grid) - Av. Mod")
```

#### Functional richness model

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
fr_75 <- glm(FRich ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid75_mets)

#dredge
frich_75_models <- dredge(fr_75, m.max = 2, 
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc))
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
frich_models_75_avg <- model.avg(frich_75_models)
summary(frich_models_75_avg)
```

```{r}
plot(frich_models_75_avg, full = FALSE, intercept = FALSE, main = "Mammal FRich (75 ha grid) - Av. Mod")
```

#### Functional evenness model

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
fe_75 <- glm(FEven ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid75_mets)

#dredge
feven_75_models <- dredge(fe_75, m.max = 2, 
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc))
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
feven_models_75_avg <- model.avg(feven_75_models)
summary(feven_models_75_avg)
```

```{r}
plot(feven_models_75_avg, full = FALSE, intercept = FALSE, main = "Mammal FEven (75 ha grid) - Av. Mod")
```

#### Functional divergence model

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
fd_75 <- glm(FDiver ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid75_mets)

#dredge
fdiver_75_models <- dredge(fd_75, m.max = 2, 
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc))
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
fdiver_models_75_avg <- model.avg(fdiver_75_models)
summary(fdiver_models_75_avg)
```

```{r}
plot(fdiver_models_75_avg, full = FALSE, intercept = FALSE, main = "Mammal FDiver (75 ha grid) - Av. Mod")
```


#### Comparing coefficient plots from averaged models

Only for shannon diveristy and functional models, based on high degree of correlation with the other community metrics
```{r fig.height=7, fig.width=6}
#extract coefficients from averaged models
coef_rich <- extract_coefs(rich_models_75_avg, "rich")
coef_shan <- extract_coefs(shan_models_75_avg, "shan")
coef_even <- extract_coefs(even_models_75_avg, "even")
coef_fric <- extract_coefs(frich_models_75_avg, "fric")
coef_feve <- extract_coefs(feven_models_75_avg, "feve")
coef_fdiv <- extract_coefs(fdiver_models_75_avg, "fdiv")

#combine all
coef_df <- rbind(coef_rich, coef_shan, coef_even, coef_fric, coef_feve, coef_fdiv)
rm(coef_rich, coef_shan, coef_even, coef_fric, coef_feve, coef_fdiv)

#specifying order to plot models
coef_df$model <- factor(coef_df$model, levels = rev(c("rich","shan","even","fric","feve","fdiv")))

#select only predictors with 50% CI's that don't overlap zero
coef_df_filter <- coef_df[!(coef_df$`2.5 %` <= 0 & coef_df$`97.5 %` >= 0),]
coef_df_filter <- coef_df_filter[!coef_df_filter$predictor %in% c("(Intercept)", "eigenvectors.sc"),]

#plotting - only the functional models for now
coef_df_filter %>%
  filter(model %in% c("rich", "shan", "fdiv", "feve")) %>%
ggplot(aes(x = estimate, y = predictor, color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(title = "Reliable Predictors from Avg. 75ha grid Models",
       x = "Coefficient Estimate", y = "") +
  theme(axis.text.y = element_text(hjust = 1),
        legend.position = "bottom") +
  guides(color = guide_legend(reverse = TRUE))
```

#### 170 ha grid

The 170 ha grid creates 10 groups (grid cells) 
```{r include=FALSE}
#species richness
#all CT locations
grid170_mets <- m_filtered %>%
  group_by(grid.170) %>%
  summarise(n.all = n_distinct(Species))

#shannon diversity
shannon_170 <- diversity(table(m_filtered$grid.170, m_filtered$Species), index = "shannon")
shannon_170 <- rownames_to_column(as.data.frame(shannon_170), var = "grid.170")
shannon_170$grid.170 <- as.integer(shannon_170$grid.170)

#species evenness
grid170_mets <- shannon_170 %>%
  left_join(., grid170_mets) %>%
  mutate(even.170 = shannon_170/log(n.all))

### functional metrics ###
#creating observation table by partition
obs_table_170 <- m_filtered %>%
  filter(Species %in% terr_traits$Species) %>%
  filter(!Species %in% c("Tragulus spp.","Unid civet","Unid Rat","Muntiacus spp.")) %>%
  group_by(grid.170, Species) %>%
  summarise(n.ind = sum(Number.of.Animals)) %>%
  pivot_wider(names_from = Species, values_from = n.ind)

#adding survey effort
ct_active_days <- grid170_cells %>%
  st_drop_geometry() %>%
  rename(grid.170 = grid_id) %>%
  dplyr::select(c(locationID, grid.170)) %>%
  left_join(ct_active_days, .)

obs_table_170 <- ct_active_days %>%
  group_by(grid.170) %>%
  summarise(act.days = sum(act.days)) %>%
  left_join(obs_table_170, ., by = "grid.170")

grid170_mets <- left_join(grid170_mets, obs_table_170[,c("grid.170", "act.days")])

#standardizing by survey effort and assigning partition to row names
#obs_table_170 <- obs_table_170 %>% mutate(across(-0, ~ . / act.days))

obs_table_170 <- as.data.frame(obs_table_170)
obs_table_170 <- obs_table_170[-13,] #drop NA row
rownames(obs_table_170) <- obs_table_170$grid.170
obs_table_170 <- obs_table_170[,-c(1, 37)]

#placing column names in alphabetical order
obs_table_170 <- obs_table_170[, order(names(obs_table_170))]

#calculating FD mets by partition
fd_metrics_170 <- dbFD(terr_traits_trim, obs_table_170)

#subset of metrics of interest
fd_metrics_170_df <- data.frame(
  grid.170 = as.numeric(rownames(as.data.frame(fd_metrics_170$FRic))), 
  FRich = fd_metrics_170$FRic, 
  FEven = fd_metrics_170$FEve, 
  FDiver = fd_metrics_170$FDiv, 
  stringsAsFactors = FALSE)

#add to metrics table
grid170_mets <- left_join(grid170_mets, fd_metrics_170_df, by = "grid.170")

#### calculating mean of all scaled predictors by grid cell
#two of the 12 cells do not have scanned locations and so will be dropped from the models below
grid170_mets <- stand_mets %>%
  group_by(grid170) %>%
  dplyr::select(ends_with(".sc")) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE)) %>%
  rename(grid.170 = grid170) %>%
  dplyr::select(-eigenvectors.sc) %>%
  left_join(grid170_mets, .)
```

Correlation of community metrics. Richness is highly correlated with FRich (0.87) and shannon is highly correlated with evenness (0.93). So probably should only keep shannon and the functional metrics. 
```{r}
chart.Correlation(grid170_mets[,c("n.all", "shannon_170", "even.170", "FRich", "FEven", "FDiver")],
                  method = "spearman")
```

Correlation of structure metrics - basal area and stand dens, basal area and mean dbh, max h and mean h, max h and vrumple, rumple and lad, 
```{r}
chart.Correlation(grid170_mets[,c("max.height.sc","sd.r.sc","CRR.rho.sc","pts.below.2m.sc",
                                    "stand.dens.sc","basal.area.sc","stem.vol.sc","mean.tree.h.sc",
                                    "mean.dbh.sc", "zentropy.sc","lad.max.sc","rumple.sc","vFRcanopy.sc",
                                    "vzrumple.sc","ClosedGapSpace.sc")],
                  method = "spearman")
```

#### Species richness model

```{r message=FALSE, warning=FALSE, include=FALSE}
#removing MO1 partition since no structure mets are from this pt
grid170_mets <- grid170_mets[complete.cases(grid170_mets),]

#fitting global model for use in dredge
rm_170 <- glm(n.all ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid170_mets)

#dredge
rich_170_models <- dredge(rm_170, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(lad.max.sc && rumple.sc))

#R-squared information
summary(rich_170_models$`adjR^2`)
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
rich_models_170_avg <- model.avg(rich_170_models)
summary(rich_models_170_avg)
```

```{r}
dev.off()
plot(rich_models_170_avg, full = FALSE, intercept = FALSE, main = "Mammal Richness (170 ha grid) - Av. Mod")
```

#### Species diversity model

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
sm_170 <- glm(shannon_170 ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid170_mets)

#dredge
shan_170_models <- dredge(sm_170, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(lad.max.sc && rumple.sc))

#R-squared information
summary(shan_170_models$`adjR^2`)
#summary(shan_170_models$`adjR^2`[shan_170_models$delta < 2])
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
shan_models_170_avg <- model.avg(shan_170_models)
summary(shan_models_170_avg)
```

```{r}
plot(shan_models_170_avg, full = FALSE, intercept = FALSE, main = "Mammal Diversity (170 ha grid) - Av. Mod")
```

#### Species eveness model

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
em_170 <- glm(even.170 ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid170_mets)

#dredge
even_170_models <- dredge(em_170, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(lad.max.sc && rumple.sc))

#R-squared information
summary(even_170_models$`adjR^2`)
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
even_models_170_avg <- model.avg(even_170_models)
summary(even_models_170_avg)
```

```{r}
plot(even_models_170_avg, full = FALSE, intercept = FALSE, main = "Mammal Evenness (170 ha grid) - Av. Mod")
```

#### Functional richness model

The beta coefficients are very large here, not sure why this is so much different from the rest of the models. Maybe an odd convergence issue?

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
fr_170 <- glm(FRich ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid170_mets)

#dredge
frich_170_models <- dredge(fr_170, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(lad.max.sc && rumple.sc))

#R-squared information
summary(frich_170_models$`adjR^2`)
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
frich_models_170_avg <- model.avg(frich_170_models)
summary(frich_models_170_avg)
```

```{r}
plot(frich_models_170_avg, full = FALSE, intercept = FALSE, main = "Mammal FRich (170 ha grid) - Av. Mod")
```

#### Functional evenness model

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
fe_170 <- glm(FEven ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid170_mets)

#dredge
feven_170_models <- dredge(fe_170, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(lad.max.sc && rumple.sc))

#R-squared information
summary(feven_170_models$`adjR^2`)
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
feven_models_170_avg <- model.avg(feven_170_models)
summary(feven_models_170_avg)
```

```{r}
plot(feven_models_170_avg, full = FALSE, intercept = FALSE, main = "Mammal FEven (170 ha grid) - Av. Mod")
```

#### Functional divergence model

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
fd_170 <- glm(FDiver ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(act.days),
           data = grid170_mets)

#dredge
fdiver_170_models <- dredge(fd_170, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(lad.max.sc && rumple.sc))

#R-squared information
summary(fdiver_170_models$`adjR^2`)
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
fdiver_models_170_avg <- model.avg(fdiver_170_models)
summary(fdiver_models_170_avg)
```

```{r}
plot(fdiver_models_170_avg, full = FALSE, intercept = FALSE, main = "Mammal FDiver (170 ha grid) - Av. Mod")
```


#### Comparing coefficient plots from averaged models

Showing only richness, shannon, FEven, and FDiver models, since FRich seemingly had nonsense results
```{r fig.height=6, fig.width=6}
#extract coefficients from averaged models
coef_rich <- extract_coefs(rich_models_170_avg, "rich")
coef_shan <- extract_coefs(shan_models_170_avg, "shan")
coef_even <- extract_coefs(even_models_170_avg, "even")
coef_fric <- extract_coefs(frich_models_170_avg, "fric")
coef_feve <- extract_coefs(feven_models_170_avg, "feve")
coef_fdiv <- extract_coefs(fdiver_models_170_avg, "fdiv")

#combine all
coef_df <- rbind(coef_rich, coef_shan, coef_even, coef_fric, coef_feve, coef_fdiv)
rm(coef_rich, coef_shan, coef_even, coef_fric, coef_feve, coef_fdiv)

#specifying order to plot models
coef_df$model <- factor(coef_df$model, levels = rev(c("rich","shan","even","fric","feve","fdiv")))

#select only predictors with 50% CI's that don't overlap zero
coef_df_filter <- coef_df[!(coef_df$`2.5 %` <= 0 & coef_df$`97.5 %` >= 0),]
coef_df_filter <- coef_df_filter[!coef_df_filter$predictor %in% c("(Intercept)", "eigenvectors.sc"),]

#plotting - only the functional models for now
coef_df_filter %>%
  filter(model %in% c("rich", "shan", "fdiv", "feve")) %>%
ggplot(aes(x = estimate, y = predictor, color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(title = "Reliable Predictors from Avg. 170ha grid Models",
       x = "Coefficient Estimate", y = "") +
  theme(axis.text.y = element_text(hjust = 1),
        legend.position = "bottom") +
  guides(color = guide_legend(reverse = TRUE))
```


### MODELS BY PARTITION

```{r include=FALSE}
#calculating mean of all scaled predictors by partition
pt_mets <- stand_mets %>%
  group_by(partition) %>%
  dplyr::select(ends_with(".sc")) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE))

ct_div_mets_terr <- left_join(ct_div_mets_terr, pt_mets)

#adding ct effort days
ct_div_mets_terr <- ct %>%
  left_join(ct_active_days) %>%
  group_by(partition) %>%
  summarise(effort = sum(act.days, na.rm = TRUE)) %>%
  filter(!partition == "Kerangas") %>%
  left_join(ct_div_mets_terr)
```

#### Check correlation between outcome variables and predictors.

Correlation of community metrics. Richness is highly correlated with FRich and shannon is highly correlated with evenness. As above, FRich shows a large outlier in one of the group averages. 
```{r}
chart.Correlation(ct_div_mets_terr[,c("n.terr", "Shannon", "evenness", "FRich", "FEven", "FDiver")],
                  method = "spearman")
```


Basal area is highly correlated (\>0.8) with stand density, max height with mean tree h and vzrumple, and vzrumple with mean tree height and rumple. 

```{r}
chart.Correlation(ct_div_mets_terr[,c("max.height.sc","sd.r.sc","CRR.rho.sc","pts.below.2m.sc",
                                    "stand.dens.sc","basal.area.sc","stem.vol.sc","mean.tree.h.sc",
                                    "mean.dbh.sc", "zentropy.sc","lad.max.sc","rumple.sc","vFRcanopy.sc",
                                    "vzrumple.sc","ClosedGapSpace.sc")],
                  method = "spearman")
```

#### Species richness model

Fitting global model then using {dredge} to find models of best fit.

Top model summary output. Restricting models to two predictors to avoid overfitting

```{r}
#removing MO1 partition since no structure mets are from this pt
ct_div_mets_terr <- ct_div_mets_terr[!ct_div_mets_terr$partition == "MO1",]
```

```{r message=FALSE, warning=FALSE, include=FALSE}
#fitting global model for use in dredge
rm_pt1 <- glm(n.terr ~ 
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(effort),
           data = ct_div_mets_terr)

#dredge
rich_pt_models <- dredge(rm_pt1, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc) && 
                               !(rumple.sc && vzrumple.sc))

#R-squared information
summary(rich_pt_models$`adjR^2`)

#selecting top model by AIC
#top_rich_pt_model <- get.models(rich_pt_models, subset = 1)
#summary(top_rich_pt_model[[1]])
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
rich_models_pt_avg <- model.avg(rich_pt_models)
summary(rich_models_pt_avg)
```

```{r}
dev.off()
plot(rich_models_pt_avg, full = FALSE, intercept = FALSE, main = "Mammal Richness (partition) - Av. Mod")
```

#### Species diversity model

Top model summary output.

```{r message=FALSE, warning=FALSE, include=FALSE}
#global model
sm_pt1 <- glm(Shannon ~  
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(effort),
           data = ct_div_mets_terr)
#dredge
shan_pt_models <- dredge(sm_pt1, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc) && 
                               !(rumple.sc && vzrumple.sc))

#R-squared information
summary(shan_pt_models$`adjR^2`)
summary(shan_pt_models$`adjR^2`[shan_pt_models$delta < 2])

#selecting top model by AIC
#top_shan_pt_model <- get.models(shan_pt_models, subset = 1)
#summary(top_shan_pt_model[[1]])
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
#averaging models
shan_models_pt_avg <- model.avg(shan_pt_models)
summary(shan_models_pt_avg)
```

```{r}
plot(shan_models_pt_avg, full = FALSE, intercept = FALSE, main = "Mammal Diversity (partition) - Av. Mod")
```

#### Species evenness model

Top model summary output.

```{r message=FALSE, warning=FALSE, include=FALSE}
#global model
em_pt1 <- glm(evenness ~  
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(effort),
           data = ct_div_mets_terr)
#dredge
even_pt_models <- dredge(em_pt1, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc) && 
                               !(rumple.sc && vzrumple.sc))

#R-squared information
summary(even_pt_models$`adjR^2`)

#selecting top model by AIC
#top_even_pt_model <- get.models(even_pt_models, subset = 1)
#summary(top_even_pt_model[[1]])
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
even_models_pt_avg <- model.avg(even_pt_models)
summary(even_models_pt_avg)
```

```{r}
plot(even_models_pt_avg, full = FALSE, intercept = FALSE, 
     main = "Terrestrial Mammal Evenness (partition) - Av. Mod")
```


#### Functional richness model

The model output here seems odd. After looking at the fric values closer, there seems to be an outlier here which may be throwing off the analysis. Not sure what to do here other than not include it in the final analysis, which may be warranted based on the high correlation between the richness and fric values (0.81)

```{r message=FALSE, warning=FALSE, include=FALSE}
#global model
frich_pt <- glm(FRich ~  
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(effort),
           data = ct_div_mets_terr)
#dredge
frich_pt_models <- dredge(frich_pt, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc) && 
                               !(rumple.sc && vzrumple.sc))

#R-squared information
summary(frich_pt_models$`adjR^2`)

#selecting top model by AIC
#top_frich_pt_model <- get.models(frich_pt_models, subset = 1)
#summary(top_frich_pt_model[[1]])
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
frich_pt_models_avg <- model.avg(frich_pt_models)
summary(frich_pt_models_avg)
```

```{r}
plot(frich_pt_models_avg, full = FALSE, intercept = FALSE, 
     main = "Functional Richness (partition) - Av. Mod")
```


#### Functional evenness model

Top model summary output.

```{r message=FALSE, warning=FALSE, include=FALSE}
#global model
feven_pt <- glm(FEven ~  
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           offset = log(effort),
           data = ct_div_mets_terr)
#dredge
feven_pt_models <- dredge(feven_pt, m.max = 2, extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc) && 
                               !(rumple.sc && vzrumple.sc))

#R-squared information
summary(feven_pt_models$`adjR^2`)

#selecting top model by AIC
#top_feven_pt_model <- get.models(feven_pt_models, subset = 1)
#summary(top_feven_pt_model[[1]])
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
feven_pt_models_avg <- model.avg(feven_pt_models)
summary(feven_pt_models_avg)
```

```{r}
plot(feven_pt_models_avg, full = FALSE, intercept = FALSE, 
     main = "Functional Evenness (partition) - Av. Mod")
```


#### Functional divergence model

Top model summary output.

```{r message=FALSE, warning=FALSE, include=FALSE}
#global model
fdiver_pt <- glm(FDiver ~  
             max.height.sc +
             mean.tree.h.sc +
             CRR.rho.sc +
             sd.r.sc +
             mean.dbh.sc +
             basal.area.sc + 
             stand.dens.sc +
             stem.vol.sc +
             pts.below.2m.sc +
             zentropy.sc +
             lad.max.sc +
             rumple.sc +
             vFRcanopy.sc +
             vzrumple.sc +
             ClosedGapSpace.sc,
           na.action = na.fail,
           family = Gamma(link = "log"), 
           #offset = log(effort),
           data = ct_div_mets_terr)
#dredge
fdiver_pt_models <- dredge(fdiver_pt, m.max = 2,  extra = "adjR^2",
                      subset = !(basal.area.sc && stand.dens.sc) && 
                               !(basal.area.sc && stem.vol.sc) && 
                               !(max.height.sc && mean.tree.h.sc) && 
                               !(max.height.sc && vzrumple.sc) && 
                               !(mean.tree.h.sc && vzrumple.sc) && 
                               !(rumple.sc && vzrumple.sc))

#R-squared information
summary(fdiver_pt_models$`adjR^2`)

#selecting top model by AIC
#top_fdiver_pt_model <- get.models(fdiver_pt_models, subset = 1)
#summary(top_fdiver_pt_model[[1]])
```

averaged model output - averaging all models

```{r message=FALSE, warning=FALSE, include=FALSE}
fdiver_pt_models_avg <- model.avg(fdiver_pt_models)
summary(fdiver_pt_models_avg)
```

```{r}
plot(fdiver_pt_models_avg, full = FALSE, intercept = FALSE, 
     main = "Functional Divergence (partition) - Av. Mod")
```


#### Comparing coefficient plot from averaged models

Since fric is highly correlated with richness (0.81) it makes sense to ignore this model here. Of the other models that have reliable predictors, the shannon and evenness values are also highly correlated (0.89) and both show vFRcanopy (vegetated volume) as the sole reliable predictor, so I also omit the evenness model here. 

```{r fig.height=5, fig.width=6}
#extract coefficients for each averaged model
coef_rich <- extract_coefs(rich_models_pt_avg, "rich")
coef_shan <- extract_coefs(shan_models_pt_avg, "shan")
coef_even <- extract_coefs(even_models_pt_avg, "even")
coef_fric <- extract_coefs(frich_pt_models_avg, "fric")
coef_feve <- extract_coefs(feven_pt_models_avg, "feve")
coef_fdiv <- extract_coefs(fdiver_pt_models_avg, "fdiv")

#combine all
coef_pt_df <- rbind(coef_rich, coef_shan, coef_even, coef_fric, coef_feve, coef_fdiv)
rm(coef_rich, coef_shan, coef_even, coef_fric, coef_feve, coef_fdiv)

#specifying order to plot models
coef_pt_df$model <- factor(coef_pt_df$model, levels = rev(c("rich","shan","even","fric","feve","fdiv")))

#select only predictors with CI's that don't overlap zero
coef_pt_df_filter <- coef_pt_df[!(coef_pt_df$`25 %` <= 0 & coef_pt_df$`75 %` >= 0),]
coef_pt_df_filter <- coef_pt_df_filter[coef_pt_df_filter$predictor != "(Intercept)",]

#plotting
coef_pt_df_filter %>%
  filter(model %in% c("shan")) %>%
ggplot(aes(x = estimate, y = predictor, color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(title = "Reliable Predictors from Averaged Partition Models",
       x = "Coefficient Estimate", y = "") +
  theme(axis.text.y = element_text(hjust = 1),
        legend.position = "bottom") +
  guides(color = guide_legend(reverse = TRUE)) +
  scale_y_discrete(labels = c("vFRcanopy.sc" = "veg. vol.",
                              "rumple.sc" = "rumple index"))
```


Comparing avg model multiplots for CT and partition scales
```{r eval=FALSE, include=FALSE}
coefplot1 <- ggplot(coef_df_filter, aes(x = estimate, y = predictor, color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(x = "", y = "") +
  theme(axis.text.y = element_text(hjust = 1),
        axis.text.x = element_blank(),
        legend.position = c(0.95, 0.5),
        legend.justification = "right") +
  guides(color = guide_legend(reverse = TRUE)) +
  scale_y_discrete(labels = c("vFRcanopy.sc" = "veg. vol.",
                              "stand.dens.sc" = "tree density",
                              "basal.area.sc" = "basal area")) +
  xlim(-0.63, 0.72)


coefplot2 <- ggplot(coef_pt_df_filter[!coef_pt_df_filter$model %in% c("fric","even"),], 
       aes(x = estimate, y = predictor, color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(x = "Coefficient Estimate", y = "") +
  theme(axis.text.y = element_text(hjust = 1),
        legend.position = "bottom") +
  guides(color = guide_legend(reverse = TRUE)) +
  scale_y_discrete(labels = c("vFRcanopy.sc" = "veg. vol.",
                              "rumple.sc" = "rumple ind. ")) +
  xlim(-0.63, 0.72)

cowplot::plot_grid(coefplot1, coefplot2, nrow = 2)
```


### Comparing effects of scale by outcome variable
```{r}
#setting global label mapping for forest structure metrics
label_mappings <- c("mean.tree.h.sc" = "tree h",
                    "rumple.sc" = "rumple index",
                    "zentropy.sc" = "vertical pt. dist.",
                    "lad.max.sc" = "leaf area dens.",
                    "CRR.rho.sc" = "canopy\nrelief ratio",
                    "ClosedGapSpace.sc" = "gap vol.",
                    "vFRcanopy.sc" = "veg. vol.",
                    "sd.r.sc" = "tree h sd",
                    "max.height.sc" = "tree h max.",
                    "stem.vol.sc" = "tree vol.",
                    "mean.dbh.sc" = "tree dbh",
                    "vzrumple.sc" = "vertical pt.\ncomplexity",
                    "stand.dens.sc" = "tree dens.",
                    "basal.area.sc" = "tree basal area",
                    "pts.below.2m.sc" = "n pts.<2m")
```


#### Species richness

```{r eval=FALSE, fig.height=9, fig.width=6, include=FALSE}
#setting custom colors for the different scales
custom_colors <- c("rich_ct" = "forestgreen",
                   "rich_pt" = "darkgreen",
                   "rich_75" = "grey",
                   "rich_170" = "grey40")

#extract coefficients from averaged models
coef_rich_ct <- extract_coefs(rich_models_avg, "rich")
coef_rich_ct$model <- "rich_ct"
coef_rich_75 <- extract_coefs(rich_models_75_avg, "rich")
coef_rich_75$model <- "rich_75"
coef_rich_170 <- extract_coefs(rich_models_170_avg, "rich")
coef_rich_170$model <- "rich_170"
coef_rich_pt <- extract_coefs(rich_models_pt_avg, "rich")
coef_rich_pt$model <- "rich_pt"

#combine all
coef_df <- rbind(coef_rich_ct, coef_rich_75, coef_rich_170, coef_rich_pt)
rm(coef_rich_ct, coef_rich_75, coef_rich_170, coef_rich_pt)

#specifying order to plot models
coef_df$model <- factor(coef_df$model, levels = rev(c("rich_ct","rich_75","rich_170","rich_pt")))

#select only predictors with 50% CI's that don't overlap zero
#coef_df_filter <- coef_df[!(coef_df$`25 %` <= 0 & coef_df$`75 %` >= 0),]
coef_df <- coef_df[!coef_df$predictor %in% c("(Intercept)", "eigenvectors.sc"),]

#plotting - only the functional models for now
ggplot(coef_df, aes(x = estimate, y = factor(predictor, levels = rev(metrics_order)), color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(title = "",
       x = "coefficient estimate", y = "", color = "scale:") +
  theme(axis.text.y = element_text(hjust = 1),
        legend.position = "bottom") +
  guides(color = guide_legend(reverse = TRUE)) +
  xlim(-3.2, 3.2) +
  scale_y_discrete(labels = label_mappings) +
  scale_color_manual(values = custom_colors,
                     labels = rev(c("eco: camera trap", 
                                      expression("grid: 0.75 km"^2), 
                                      expression("grid: 1.7 km"^2),
                                  "eco: forest type partition")))

#ggsave("rich_multiplot.jpg", plot = last_plot(), width = 7.5, height = 9.5, dpi = 500, device = "jpeg")
```

#### Shannon diversity

```{r fig.height=9, fig.width=6}
#setting custom colors for the different scales
custom_colors <- c("shan_ct" = "forestgreen",
                   "shan_pt" = "darkgreen",
                   "shan_75" = "grey",
                   "shan_170" = "grey40")

#extract coefficients from averaged models
coef_shan_ct <- extract_coefs(shan_models_avg, "shan")
coef_shan_ct$model <- "shan_ct"
coef_shan_75 <- extract_coefs(shan_models_75_avg, "shan")
coef_shan_75$model <- "shan_75"
coef_shan_170 <- extract_coefs(shan_models_170_avg, "shan")
coef_shan_170$model <- "shan_170"
coef_shan_pt <- extract_coefs(shan_models_pt_avg, "shan")
coef_shan_pt$model <- "shan_pt"

#combine all
coef_df <- rbind(coef_shan_ct, coef_shan_75, coef_shan_170, coef_shan_pt)
rm(coef_shan_ct, coef_shan_75, coef_shan_170, coef_shan_pt)

#specifying order to plot models
coef_df$model <- factor(coef_df$model, levels = rev(c("shan_ct","shan_pt","shan_75","shan_170")))

#select only predictors with 50% CI's that don't overlap zero
#coef_df_filter <- coef_df[!(coef_df$`25 %` <= 0 & coef_df$`75 %` >= 0),]
coef_df <- coef_df[!coef_df$predictor %in% c("(Intercept)", "eigenvectors.sc"),]

#plotting - only the functional models for now
metrics_order <- c("mean.tree.h.sc","rumple.sc","zentropy.sc","lad.max.sc","CRR.rho.sc",
                   "ClosedGapSpace.sc","vFRcanopy.sc","sd.r.sc","max.height.sc","stem.vol.sc",
                   "mean.dbh.sc","vzrumple.sc","stand.dens.sc","basal.area.sc","pts.below.2m.sc")

ggplot(coef_df, aes(x = estimate, y = factor(predictor, levels = rev(metrics_order)), color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  geom_hline(yintercept = 8.5, color = "grey40") +
  geom_hline(yintercept = 4.5, color = "grey40") +
  theme_classic() +
  labs(title = "",
       x = "coefficient estimate", y = "", color = "scale:") +
  theme(axis.text.y = element_text(hjust = 1), legend.position = "bottom",
        legend.text = element_text(size = 9)) +
  guides(color = guide_legend(reverse = TRUE)) +
  coord_cartesian(xlim = c(-3, 2.6)) +
  annotate("text", x = 1.9, y = 12, 
           label = "opposite direction\n of effects\n (eco. scales\n vs. grid scales)", 
           color = "grey30", size = 3, fontface = "bold") +
  annotate("text", x = 1.9, y = 6.5, 
           label = "same direction\n of effects", 
           color = "grey30", size = 3, fontface = "bold")  +
  annotate("text", x = 1.9, y = 2.5, 
           label = "mixed direction\n of effects", 
           color = "grey30", size = 3, fontface = "bold") +
  scale_color_manual(values = custom_colors,
                     labels = rev(c("eco: camera trap", 
                                      expression("grid: 0.75 km"^2), 
                                      expression("grid: 1.7 km"^2),
                                  "eco: forest type partition"))) +
  scale_y_discrete(labels = label_mappings)

#ggsave("shan_multiplot.jpg", plot = last_plot(), width = 7.5, height = 9.5, dpi = 500, device = "jpeg")
```


Again for Shannon diversity, but reliable predictors only
```{r fig.height=7, fig.width=6}
#again, just showing the reliable predictors
#select only predictors with 50% CI's that don't overlap zero
coef_df_filter <- coef_df[!(coef_df$`2.5 %` <= 0 & coef_df$`97.5 %` >= 0),]
coef_df_filter <- coef_df_filter[!coef_df_filter$predictor %in% c("(Intercept)", "eigenvectors.sc"),]

coef_df_filter %>%
  #filter(model %in% c("rich_ct", "rich_pt")) %>%
ggplot(aes(x = estimate, y = factor(predictor, levels = rev(metrics_order)), color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(title = "Shannon Diversity Reliable Predictors at Different Scales",
       x = "Coefficient Estimate", y = "") +
  theme(axis.text.y = element_text(hjust = 1), legend.position = "bottom",
        legend.text = element_text(size = 9)) +
  guides(color = guide_legend(reverse = TRUE))
```

#### Species evenness

```{r eval=FALSE, fig.height=9, fig.width=6, include=FALSE}
#setting custom colors for the different scales
custom_colors <- c("even_ct" = "forestgreen",
                   "even_pt" = "darkgreen",
                   "even_75" = "grey",
                   "even_170" = "grey40")

#extract coefficients from averaged models
coef_even_ct <- extract_coefs(even_models_avg, "even")
coef_even_ct$model <- "even_ct"
coef_even_75 <- extract_coefs(even_models_75_avg, "even")
coef_even_75$model <- "even_75"
coef_even_170 <- extract_coefs(even_models_170_avg, "even")
coef_even_170$model <- "even_170"
coef_even_pt <- extract_coefs(even_models_pt_avg, "even")
coef_even_pt$model <- "even_pt"

#combine all
coef_df <- rbind(coef_even_ct, coef_even_75, coef_even_170, coef_even_pt)
rm(coef_even_ct, coef_even_75, coef_even_170, coef_even_pt)

#specifying order to plot models
coef_df$model <- factor(coef_df$model, levels = rev(c("even_ct","even_75","even_170","even_pt")))

#select only predictors with 50% CI's that don't overlap zero
#coef_df_filter <- coef_df[!(coef_df$`25 %` <= 0 & coef_df$`75 %` >= 0),]
coef_df <- coef_df[!coef_df$predictor %in% c("(Intercept)", "eigenvectors.sc"),]

#plotting - only the functional models for now
ggplot(coef_df, aes(x = estimate, y = factor(predictor, levels = rev(metrics_order)), color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(title = "",
       x = "coefficient estimate", y = "", color = "scale:") +
  theme(axis.text.y = element_text(hjust = 1),
        legend.position = "bottom") +
  guides(color = guide_legend(reverse = TRUE)) +
  #xlim(-3.1, 3.1) +
  scale_y_discrete(labels = label_mappings) +
  scale_color_manual(values = custom_colors,
                     labels = rev(c("eco: camera trap", 
                                      expression("grid: 0.75 km"^2), 
                                      expression("grid: 1.7 km"^2),
                                  "eco: forest type partition")))

#ggsave("even_multiplot.jpg", plot = last_plot(), width = 7.5, height = 9.5, dpi = 500, device = "jpeg")
```

#### Functional richness

```{r eval=FALSE, fig.height=9, fig.width=6, include=FALSE}
#setting custom colors for the different scales
custom_colors <- c("Fric_ct" = "forestgreen",
                   "Fric_pt" = "darkgreen",
                   "Fric_75" = "grey",
                   "Fric_170" = "grey40")

#extract coefficients from averaged models
coef_Fric_ct <- extract_coefs(frich_models_avg, "fric")
coef_Fric_ct$model <- "Fric_ct"
coef_Fric_75 <- extract_coefs(frich_models_75_avg, "fric")
coef_Fric_75$model <- "Fric_75"
coef_Fric_170 <- extract_coefs(frich_models_170_avg, "fric")
coef_Fric_170$model <- "Fric_170"
coef_Fric_pt <- extract_coefs(frich_pt_models_avg, "fric")
coef_Fric_pt$model <- "Fric_pt"

#combine all
coef_df <- rbind(coef_Fric_ct, coef_Fric_75, coef_Fric_170, coef_Fric_pt)
rm(coef_Fric_ct, coef_Fric_75, coef_Fric_170, coef_Fric_pt)

#specifying order to plot models
coef_df$model <- factor(coef_df$model, levels = rev(c("Fric_ct","Fric_75","Fric_170","Fric_pt")))

#select only predictors with 50% CI's that don't overlap zero
#coef_df_filter <- coef_df[!(coef_df$`25 %` <= 0 & coef_df$`75 %` >= 0),]
coef_df <- coef_df[!coef_df$predictor %in% c("(Intercept)", "eigenvectors.sc"),]

#plotting - only the functional models for now
coef_df %>%
  #filter(model %in% c("Fric_ct", "Fric_75")) %>%
ggplot(aes(x = estimate, y = factor(predictor, levels = rev(metrics_order)), color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(title = "",
       x = "coefficient estimate", y = "", color = "scale:") +
  theme(axis.text.y = element_text(hjust = 1),
        legend.position = "bottom") +
  guides(color = guide_legend(reverse = TRUE)) +
  scale_y_discrete(labels = label_mappings) +
  scale_color_manual(values = custom_colors,
                     labels = rev(c("eco: camera trap", 
                                      expression("grid: 0.75 km"^2), 
                                      expression("grid: 1.7 km"^2),
                                  "eco: forest type partition")))

#ggsave("fric_multiplot.jpg", plot = last_plot(), width = 7.5, height = 9.5, dpi = 500, device = "jpeg")
```

#### Functional evenness

```{r eval=FALSE, fig.height=9, fig.width=6, include=FALSE}
#setting custom colors for the different scales
custom_colors <- c("Feve_ct" = "forestgreen",
                   "Feve_pt" = "darkgreen",
                   "Feve_75" = "grey",
                   "Feve_170" = "grey40")

#extract coefficients from averaged models
coef_Feve_ct <- extract_coefs(feven_models_avg, "feve")
coef_Feve_ct$model <- "Feve_ct"
coef_Feve_75 <- extract_coefs(feven_models_75_avg, "feve")
coef_Feve_75$model <- "Feve_75"
coef_Feve_170 <- extract_coefs(feven_models_170_avg, "feve")
coef_Feve_170$model <- "Feve_170"
coef_Feve_pt <- extract_coefs(feven_pt_models_avg, "feve")
coef_Feve_pt$model <- "Feve_pt"

#combine all
coef_df <- rbind(coef_Feve_ct, coef_Feve_75, coef_Feve_170, coef_Feve_pt)
rm(coef_Feve_ct, coef_Feve_75, coef_Feve_170, coef_Feve_pt)

#specifying order to plot models
coef_df$model <- factor(coef_df$model, levels = rev(c("Feve_ct","Feve_75","Feve_170","Feve_pt")))

#select only predictors with 50% CI's that don't overlap zero
#coef_df_filter <- coef_df[!(coef_df$`25 %` <= 0 & coef_df$`75 %` >= 0),]
coef_df <- coef_df[!coef_df$predictor %in% c("(Intercept)", "eigenvectors.sc"),]

#plotting - only the functional models for now
ggplot(coef_df, aes(x = estimate, y = factor(predictor, levels = rev(metrics_order)), color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(title = "",
       x = "coefficient estimate", y = "", color = "scale:") +
  theme(axis.text.y = element_text(hjust = 1),
        legend.position = "bottom") +
  guides(color = guide_legend(reverse = TRUE)) +
  scale_y_discrete(labels = label_mappings) +
  scale_color_manual(values = custom_colors,
                     labels = rev(c("eco: camera trap", 
                                      expression("grid: 0.75 km"^2), 
                                      expression("grid: 1.7 km"^2),
                                  "eco: forest type partition")))

#ggsave("feve_multiplot.jpg", plot = last_plot(), width = 7.5, height = 9.5, dpi = 500, device = "jpeg")
```

#### Functional divergence

```{r eval=FALSE, fig.height=9, fig.width=6, include=FALSE}
#setting custom colors for the different scales
custom_colors <- c("Fdiv_ct" = "forestgreen",
                   "Fdiv_pt" = "darkgreen",
                   "Fdiv_75" = "grey",
                   "Fdiv_170" = "grey40")

#extract coefficients from averaged models
coef_Fdiv_ct <- extract_coefs(fdiver_models_avg, "fdiv")
coef_Fdiv_ct$model <- "Fdiv_ct"
coef_Fdiv_75 <- extract_coefs(fdiver_models_75_avg, "fdiv")
coef_Fdiv_75$model <- "Fdiv_75"
coef_Fdiv_170 <- extract_coefs(fdiver_models_170_avg, "fdiv")
coef_Fdiv_170$model <- "Fdiv_170"
coef_Fdiv_pt <- extract_coefs(fdiver_pt_models_avg, "fdiv")
coef_Fdiv_pt$model <- "Fdiv_pt"

#combine all
coef_df <- rbind(coef_Fdiv_ct, coef_Fdiv_75, coef_Fdiv_170, coef_Fdiv_pt)
rm(coef_Fdiv_ct, coef_Fdiv_75, coef_Fdiv_170, coef_Fdiv_pt)

#specifying order to plot models
coef_df$model <- factor(coef_df$model, levels = rev(c("Fdiv_ct","Fdiv_75","Fdiv_170","Fdiv_pt")))

#select only predictors with 50% CI's that don't overlap zero
#coef_df_filter <- coef_df[!(coef_df$`25 %` <= 0 & coef_df$`75 %` >= 0),]
coef_df <- coef_df[!coef_df$predictor %in% c("(Intercept)", "eigenvectors.sc"),]

#plotting - only the functional models for now
ggplot(coef_df, aes(x = estimate, y = factor(predictor, levels = rev(metrics_order)), color = model)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(xmin = `2.5 %`, xmax = `97.5 %`), width = 0, 
                position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = `25 %`, xmax = `75 %`), width = 0, 
                position = position_dodge(width = 0.5), size = 1.5, linetype = "solid") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  theme_classic() +
  labs(title = "",
       x = "coefficient estimate", y = "", color = "model scale:") +
  theme(axis.text.y = element_text(hjust = 1),
        legend.position = "bottom") +
  guides(color = guide_legend(reverse = TRUE)) +
  scale_y_discrete(labels = label_mappings) +
  scale_color_manual(values = custom_colors,
                     labels = rev(c("eco: camera trap", 
                                      expression("grid: 0.75 km"^2), 
                                      expression("grid: 1.7 km"^2),
                                  "eco: forest type partition")))

#ggsave("fdiv_multiplot.jpg", plot = last_plot(), width = 7.5, height = 9.5, dpi = 500, device = "jpeg")
```


## ORDINATION ANALYSIS

Using PCA to see how scan locations group together and to identify which forest structure metrics best differentiate between forest types and partitions.
```{r echo=FALSE, message=FALSE, warning=FALSE}
#run PCA
pca_result <- prcomp(stand_mets[,c("max.height",
                                   "sd.r",
                                   "CRR.rho",
                                   "pts.below.2m",
                                   "stand.dens",
                                   "basal.area",
                                   "stem.vol",
                                   "mean.tree.h",
                                   "mean.dbh",
                                   "zentropy",
                                   "lad.max",
                                   "rumple",
                                   "vFRcanopy",
                                   "vzrumple",
                                   "ClosedGapSpace")], 
                     scale. = TRUE)

#PCA scores
pca_scores <- as.data.frame(pca_result$x[, 1:2])
colnames(pca_scores) <- c("PC1", "PC2")

#add forest type and partition to pca_score table
pca_scores$ForestType <- stand_mets$habitat
pca_scores$partition <- stand_mets$partition

#calculate percentage of variance explained by each principal component
pca_var <- summary(pca_result)$importance[2, ]

#visualize eigenvalues (scree plot) - shows many dimensions explain much variance
fviz_eig(pca_result)

#plot PCA results with ellipses using ggplot2
ggplot(pca_scores, aes(x = PC1, y = PC2, color = as.factor(partition))) +
  geom_point(size = 3) +
  stat_ellipse(level = 0.95, aes(fill = as.factor(ForestType)), alpha = 0.2, geom = "polygon") +
  theme_classic() +
  labs(color = "partition", fill = "partition", title = "PCA of Forest Structure Metrics") +
  guides(color = guide_legend(reverse = TRUE), fill = guide_legend(reverse = TRUE))
```


Which structure metrics best differentiate between locations?
```{r echo=FALSE, message=FALSE, warning=FALSE}
fviz_pca_var(pca_result,
             col.var = "contrib",
             gradient.cols = c("grey", "forestgreen", "black"),
             repel = TRUE)
```

Table of variable PCA contribution values 
```{r}
get_pca_var(pca_result)$contrib %>%
  as.data.frame() %>%
  rowwise() %>%
  mutate(total_contrib = sum(c_across(starts_with("Dim.1") | starts_with("Dim.2")))) %>%
  ungroup() %>%
  mutate(variable = rownames(get_pca_var(pca_result)$contrib)) %>%
  dplyr::select(variable, total_contrib) %>%
  arrange(desc(total_contrib))
```


## BIVARIATE PLOTS

### terrestrial mammals (ct data) by ct location

Structure metrics X species richness

```{r}
#selecting only metrics of interest
fs_mets <- c("max.height", "sd.r", "CRR.rho", "pts.below.2m", "stand.dens", "basal.area", "stem.vol", "mean.tree.h", "mean.dbh", "zentropy", "lad.max", "rumple", "vFRcanopy", "vzrumple", "ClosedGapSpace")

stand_mets %>%
  dplyr::select(location, n.all, shannon_ct, div_even, all_of(fs_mets)) %>%
  pivot_longer(cols = fs_mets, 
               names_to = "metric", 
               values_to = "value") %>%
  group_by(metric) %>%
  mutate(cor = cor(value, n.all, method = "spearman", use = "complete.obs"),
         subtitle = paste("Spearman's r =", round(cor, 2))) %>%
  ggplot(aes(x = value, y = n.all)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x), se = FALSE, color = "cornflowerblue") +
  facet_wrap(~ metric, scales = "free_x") +
  labs(x = "Structure Metric Value", y = "Species Richness") +
  theme_minimal() +
  geom_text(data = . %>% group_by(metric) %>% summarise(cor = unique(cor)),
            aes(label = paste("Spearman's r =", round(cor, 2)), x = Inf, y = -Inf),
            hjust = 1.1, vjust = -1.1, color = "black", size = 3, 
            position = position_nudge(x = -0.5, y = 0.5))
```


Structure metrics X Shannon diversity

```{r}
stand_mets %>%
  dplyr::select(location, n.all, shannon_ct, div_even, all_of(fs_mets)) %>%
  pivot_longer(cols = all_of(fs_mets), 
               names_to = "metric", 
               values_to = "value") %>%
  group_by(metric) %>%
  mutate(cor = cor(value, shannon_ct, method = "spearman", use = "complete.obs"),
         subtitle = paste("Spearman's r =", round(cor, 2))) %>%
  ggplot(aes(x = value, y = shannon_ct)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x), se = FALSE, color = "cornflowerblue") +
  facet_wrap(~ metric, scales = "free_x") +
  labs(x = "Structure Metric Value", y = "Shannon Diversity") +
  theme_minimal() +
  geom_text(data = . %>% group_by(metric) %>% summarise(cor = unique(cor)),
            aes(label = paste("Spearman's r =", round(cor, 2)), x = Inf, y = -Inf),
            hjust = 1.1, vjust = -1.1, color = "black", size = 3, 
            position = position_nudge(x = -0.5, y = 0.5))
```

Structure metrics X Species Evenness

```{r}
stand_mets %>%
  dplyr::select(location, n.all, shannon_ct, div_even, all_of(fs_mets)) %>%
  pivot_longer(cols = all_of(fs_mets), 
               names_to = "metric", 
               values_to = "value") %>%
  group_by(metric) %>%
  mutate(cor = cor(value, div_even, method = "spearman", use = "complete.obs"),
         subtitle = paste("Spearman's r =", round(cor, 2))) %>%
  ggplot(aes(x = value, y = div_even)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x), se = FALSE, color = "cornflowerblue") +
  facet_wrap(~ metric, scales = "free_x") +
  labs(x = "Structure Metric Value", y = "Species Evenness") +
  theme_minimal() +
  geom_text(data = . %>% group_by(metric) %>% summarise(cor = unique(cor)),
            aes(label = paste("Spearman's r =", round(cor, 2)), x = Inf, y = -Inf),
            hjust = 1.1, vjust = -1.1, color = "black", size = 3, 
            position = position_nudge(x = -0.5, y = 0.5))
```

Structure metrics X Functional Richness

```{r}
stand_mets %>%
  dplyr::select(location, FRich, FEven, FDiver, all_of(fs_mets)) %>%
  pivot_longer(cols = all_of(fs_mets), 
               names_to = "metric", 
               values_to = "value") %>%
  group_by(metric) %>%
  mutate(cor = cor(value, FRich, method = "spearman", use = "complete.obs"),
         subtitle = paste("Spearman's r =", round(cor, 2))) %>%
  ggplot(aes(x = value, y = FRich)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x), se = FALSE, color = "cornflowerblue") +
  facet_wrap(~ metric, scales = "free_x") +
  labs(x = "Structure Metric Value", y = "Functional Richness") +
  theme_minimal() +
  geom_text(data = . %>% group_by(metric) %>% summarise(cor = unique(cor)),
            aes(label = paste("Spearman's r =", round(cor, 2)), x = Inf, y = -Inf),
            hjust = 1.1, vjust = -1.1, color = "black", size = 3, 
            position = position_nudge(x = -0.5, y = 0.5))
```

Structure metrics X Functional Evenness

```{r}
stand_mets %>%
  dplyr::select(location, FRich, FEven, FDiver, all_of(fs_mets)) %>%
  pivot_longer(cols = all_of(fs_mets), 
               names_to = "metric", 
               values_to = "value") %>%
  group_by(metric) %>%
  mutate(cor = cor(value, FEven, method = "spearman", use = "complete.obs"),
         subtitle = paste("Spearman's r =", round(cor, 2))) %>%
  ggplot(aes(x = value, y = FEven)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x), se = FALSE, color = "cornflowerblue") +
  facet_wrap(~ metric, scales = "free_x") +
  labs(x = "Structure Metric Value", y = "Functional Evenness") +
  theme_minimal() +
  geom_text(data = . %>% group_by(metric) %>% summarise(cor = unique(cor)),
            aes(label = paste("Spearman's r =", round(cor, 2)), x = Inf, y = -Inf),
            hjust = 1.1, vjust = -1.1, color = "black", size = 3, 
            position = position_nudge(x = -0.5, y = 0.5))
```

Structure metrics X Functional Divergence

```{r}
stand_mets %>%
  dplyr::select(location, FRich, FEven, FDiver, all_of(fs_mets)) %>%
  pivot_longer(cols = all_of(fs_mets), 
               names_to = "metric", 
               values_to = "value") %>%
  group_by(metric) %>%
  mutate(cor = cor(value, FDiver, method = "spearman", use = "complete.obs"),
         subtitle = paste("Spearman's r =", round(cor, 2))) %>%
  ggplot(aes(x = value, y = FDiver)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x), se = FALSE, color = "cornflowerblue") +
  facet_wrap(~ metric, scales = "free_x") +
  labs(x = "Structure Metric Value", y = "Functional Divergence") +
  theme_minimal() +
  geom_text(data = . %>% group_by(metric) %>% summarise(cor = unique(cor)),
            aes(label = paste("Spearman's r =", round(cor, 2)), x = Inf, y = -Inf),
            hjust = 1.1, vjust = -1.1, color = "black", size = 3, 
            position = position_nudge(x = -0.5, y = 0.5))
```


### terrestrial mammals (ct data) by partition

Structure metrics X species richness

```{r}
ct_div_mets_terr %>%
  pivot_longer(cols = c(9:27), names_to = "metric", values_to = "value") %>%
  group_by(metric) %>%
  mutate(cor = cor(value, n.terr, method = "spearman", use = "complete.obs"),
         subtitle = paste("Spearman's r =", round(cor, 2))) %>%
  ggplot(aes(x = value, y = n.terr)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x), se = FALSE, color = "cornflowerblue") +
  facet_wrap(~ metric, scales = "free_x") +
  labs(x = "Structure Metric Value", y = "Species Richness") +
  theme_minimal() +
  geom_text(data = . %>% group_by(metric) %>% summarise(cor = unique(cor)),
            aes(label = paste("Spearman's r =", round(cor, 2)), x = Inf, y = -Inf),
            hjust = 1.1, vjust = -1.1, color = "black", size = 3, 
            position = position_nudge(x = -0.5, y = 0.5))
```


Structure metrics X Shannon diversity

```{r}
ct_div_mets_terr %>%
  pivot_longer(cols = c(9:27), names_to = "metric", values_to = "value") %>%
  group_by(metric) %>%
  mutate(cor = cor(value, Shannon, method = "spearman", use = "complete.obs"),
         subtitle = paste("Spearman's r =", round(cor, 2))) %>%
  ggplot(aes(x = value, y = Shannon)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x), se = FALSE, color = "cornflowerblue") +
  facet_wrap(~ metric, scales = "free_x") +
  labs(x = "Structure Metric Value", y = "Shannon Diversity") +
  theme_minimal() +
  geom_text(data = . %>% group_by(metric) %>% summarise(cor = unique(cor)),
            aes(label = paste("Spearman's r =", round(cor, 2)), x = Inf, y = -Inf),
            hjust = 1.1, vjust = -1.1, color = "black", size = 3, 
            position = position_nudge(x = -0.5, y = 0.5))
```

Structure metrics X Species Evenness

```{r}
ct_div_mets_terr %>%
  pivot_longer(cols = c(9:27), names_to = "metric", values_to = "value") %>%
  group_by(metric) %>%
  mutate(cor = cor(value, evenness, method = "spearman", use = "complete.obs"),
         subtitle = paste("Spearman's r =", round(cor, 2))) %>%
  ggplot(aes(x = value, y = evenness)) +
  geom_point() +
  geom_smooth(method = "gam", formula = y ~ s(x), se = FALSE, color = "cornflowerblue") +
  facet_wrap(~ metric, scales = "free_x") +
  labs(x = "Structure Metric Value", y = "Species Evenness") +
  theme_minimal() +
  geom_text(data = . %>% group_by(metric) %>% summarise(cor = unique(cor)),
            aes(label = paste("Spearman's r =", round(cor, 2)), x = Inf, y = -Inf),
            hjust = 1.1, vjust = -1.1, color = "black", size = 3, 
            position = position_nudge(x = -0.5, y = 0.5))
```


summary table for Pearson correlation between structure metrics and diversity metrics
```{r}
#creating matrix for vars at the CT scale
divmets <- c("n.all", "shannon_ct", "div_even", "FRich", "FEven", "FDiver")

cor_matrix <- matrix(nrow = length(fs_mets), ncol = length(divmets))
rownames(cor_matrix) <- fs_mets
colnames(cor_matrix) <- divmets

#calculate Pearson correlation coefficients
for (i in 1:length(fs_mets)) {
  for (j in 1:length(divmets)) {
    cor_matrix[i, j] <- cor(stand_mets[[fs_mets[i]]], stand_mets[[divmets[j]]], 
                            method = "pearson", use = "complete.obs")
  }
}

#creating matrix for vars at the partition scale
divmets <- c("n.terr", "Shannon", "evenness", "FRich", "FEven", "FDiver")

cor_matrix2 <- matrix(nrow = length(fs_mets), ncol = length(divmets))
rownames(cor_matrix2) <- paste0(fs_mets, ".sc")
colnames(cor_matrix2) <- divmets

#calculate Pearson correlation coefficients
for (i in 1:length(fs_mets)) {
  for (j in 1:length(divmets)) {
    cor_matrix2[i, j] <- cor(ct_div_mets_terr[[paste0(fs_mets, ".sc")[i]]], ct_div_mets_terr[[divmets[j]]], method = "pearson")
  }
}

#combining matrices and changing model names for clarity
cor_df <- as.data.frame(cbind(cor_matrix, cor_matrix2))
colnames(cor_df) <- c("Richness", "Shannon Diversity", "Evenness", 
                      "Func. Richness", "Func. Evenness", "Func. Divergence",
                      "Richness", "Shannon Diversity", "Evenness", 
                      "Func. Richness", "Func. Evenness", "Func. Divergence")

#create table
kbl(cor_df, format = "html", 
    caption = "Pearson correlations beteen structure metrics and diversity metrics") %>%
  kable_styling(bootstrap_options = "striped") %>%
  add_header_above(c(" " = 1, "Camera Trap Scale" = 6, "Partition Scale" = 6))
```


## Spatial heterogeneity in the grid systems compared to partitions

How do forest types and partitions map on to the grid systems created above?

In the 75 ha grid system, cells contain between 1 and 6 partitions, with an average of 2.8 paritions per cell. In the 170 ha grid system this range is 2 - 7 with an average of 3.2. 
```{r}
#read in the forest type and partitions by grid cell data
grid_int <- read.csv(file = "data/grids_intersect.csv", header = TRUE)

#remove heath forests
grid_int <- grid_int[!grid_int$habitat == "Heath",]

#number and avg. of partitions in each cell of the two grid systems
table(grid_int$grid_id[grid_int$grid_size == 75])
mean(table(grid_int$grid_id[grid_int$grid_size == 75]))

table(grid_int$grid_id[grid_int$grid_size == 170])
mean(table(grid_int$grid_id[grid_int$grid_size == 170]))
```

What proportion of partitions are within each cell of the two grid systems? I still need to choose a color scheme for the partitions, something that matches the forest type colors. 
```{r}
#calculate partition proportions
grid_int <- grid_int %>%
  group_by(grid_size, grid_id) %>%
  mutate(prop = Shape_Area / sum(Shape_Area))

#ordering partitions
grid_int$partition <- factor(grid_int$partition, levels = rev(c("PS1", "FS1", "AB1", "AB2",
                                          "LS1", "LS2","LG1","LG2", "UG1","UG2", "MO1", "MO2")),
                    ordered = TRUE)

#setting custom colors that match the forest type map
partition_colors <- c("PS1" = "#401D00", 
                      "FS1" = "#643E00", 
                      "AB1" = "#896007", 
                      "AB2" = alpha("#896007", 0.7),
                      "LS1" = "#AF8228", 
                      "LS2" = alpha("#AF8228", 0.7), 
                      "LG1" = "#D3A43B", 
                      "LG2" = alpha("#D3A43B", 0.7), 
                      "UG1" = "#F4C444",
                      "UG2" = alpha("#F4C444", 0.7), 
                      "MO1" = "#FFDD2D", 
                      "MO2" = alpha("#FFDD2D", 0.7))

#plot for 75 ha grid
p1 <- ggplot(grid_int[grid_int$grid_size == 75,],
       aes(x = factor(grid_id), y = prop, fill = partition)) +
  geom_bar(stat = "identity") +
  labs(title = expression("0.75 km"^2*"grid scale"), 
       x = "grid cell ID", y = "proportion of forest type partition", 
       fill = "partition") +
  theme_classic() +
  coord_flip() +
  scale_fill_manual(values = partition_colors) +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5))

#plot for 170 ha grid
p2 <- ggplot(grid_int[grid_int$grid_size == 170,],
       aes(x = factor(grid_id), y = prop, fill = partition)) +
  geom_bar(stat = "identity") +
  labs(title = expression("1.7 km"^2*"grid scale"), 
       x = "", y = "proportion of forest type partition", 
       fill = "partition") +
  theme_classic() +
  coord_flip() +
  scale_fill_manual(values = partition_colors) +
  theme(plot.title = element_text(hjust = 0.5))

cowplot::plot_grid(p1, p2,nrow = 1, rel_widths = c(.4, .55))
```


How does variation in structure metrics compare between scales? The table shows the average adjusted coefficient of variation (which controls for sample size) of structure metrics across cells and partitions, comparing across the different scales. If grid systems are capturing more ecological variation in these metrics compared to forest type partitions, then we would expect the 170 ha grid average values to be larger than those at the partition scale. This is indeed what we see, with most (12/15) structure metrics and half (3/6) community metrics showing less variation at the partition scale than the comparable 170 ha grid scale. 
```{r}
metric_list_FD <- c(metric_list, "FRich", "FEven", "FDiver")
stand_mets$study.area <- 1

#function to calculate adjusted coefficient of variation
calculate_adj_cv <- function(x) {
  N <- length(x[!is.na(x)])
  if (N > 1) {
    mean_x <- mean(x, na.rm = TRUE)
    sd_x <- sd(x, na.rm = TRUE)
    adj_cv <- (1 + 1 / (4 * N)) * (sd_x / mean_x)
    return(adj_cv)
  } else {
    return(NA)
  }
}

summarize_adj_cv <- function(data, scale_column) {
  data %>%
    group_by(!!sym(scale_column)) %>%
    summarize(across(all_of(metric_list_FD), ~ calculate_adj_cv(.x))) %>%
    summarize(across(all_of(metric_list_FD), list(mean_adj_cv = ~ mean(.x, na.rm = TRUE))))
}

#calculate adj CV summary stats for each scale and entire study area
summary_75ha <- summarize_adj_cv(stand_mets, "grid75")
summary_170ha <- summarize_adj_cv(stand_mets, "grid170")
summary_650ha <- summarize_adj_cv(stand_mets, "grid650")
summary_partition <- stand_mets %>%
  mutate(across(c("grid75", "grid170", "grid650", "partition"), as.numeric)) %>%
  summarize_adj_cv(., "partition")
summary_all <- summarize_adj_cv(stand_mets, "study.area")


#combine
adjCV_mets <- bind_rows(summary_75ha %>% mutate(scale = "75 ha"),
  summary_170ha %>% mutate(scale = "170 ha"),
  summary_650ha %>% mutate(scale = "650 ha"),
  summary_partition %>% mutate(scale = "partition"),
  summary_all %>% mutate(scale = "study area")) %>%
  pivot_longer(cols = -scale, names_to = "metric_stat", values_to = "value") %>%
  separate(metric_stat, into = c("metric", "stat"), sep = "_mean") %>%
  pivot_wider(names_from = scale, values_from = value) %>%
  mutate("pt<170ha" = partition < `170 ha`,
         "75<170" = `75 ha` < `170 ha`,
         "170<650" = `170 ha` < `650 ha`,
         "650<SA" = `650 ha` < `study area`,
         "75<SA" = `75 ha` < `study area`) %>%
  print(n = Inf)
```


Figure showing how average adjusted coefficient of variation (which controls for number of camera trap locations in each cell) increases as grid size increases across the 15 forest structure metrics. Some metrics reach a peak at 170 or 650 ha scale, and don't show more variation even at the study area scale. However, all but one of the metrics (mean dbh; highlighted) increase in variation from the 75 ha to the study area scale.  
```{r fig.height=7, fig.width=5}
adjCV_mets %>%
  filter(!metric %in% c("n.all", "shannon_ct", "div_even", "FRich", "FEven", "FDiver")) %>%
  pivot_longer(cols = c(`75 ha`, `170 ha`, `650 ha`, `study area`), 
               names_to = "scale", values_to = "value") %>%
  mutate(scale = factor(scale, 
                        levels = c("75 ha", "170 ha", "650 ha", "study area")),
         metric_label = recode(metric, 
                              "mean.tree.h" = "tree h",
                              "rumple" = "rumple",
                              "zentropy" = "v dist.",
                              "lad.max" = "LAD",
                              "CRR.rho" = "CRR",
                              "ClosedGapSpace" = "gap vol.",
                              "vFRcanopy" = "veg. vol.",
                              "sd.r" = "tree h sd",
                              "max.height" = "tree h max.",
                              "stem.vol" = "tree vol.",
                              "mean.dbh" = "tree dbh",
                              "vzrumple" = "v complex.",
                              "stand.dens" = "tree dens.",
                              "basal.area" = "basal area",
                              "pts.below.2m" = "n pts<2m"),
         label_y = case_when(
           metric_label == "tree dens." ~ value + 0.01,
           metric_label == "veg. vol." ~ value + 0.01,
           metric_label == "tree h sd" ~ value + 0.01,
           TRUE ~ value)) %>%
  ggplot(aes(x = scale, y = value, group = metric, color = `75<SA`)) +
  geom_point(size = 3) +
  geom_line() +
  geom_text(data = . %>% filter(scale == "study area"), 
            aes(label = metric_label, y = label_y), 
            hjust = -0.3, 
            size = 3) +
  labs(x = "grid scales", y = "adj. coefficient of variation") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_x_discrete(labels = c("75 ha" = expression("0.75 km"^2), 
                              "170 ha" = expression("1.7 km"^2), 
                              "650 ha" = expression("6.5 km"^2), 
                              "study area" = expression("study area (26 km"^2*")")))
```


Again but using facet wrap
```{r}
#adjusted function
summarize_adj_cv2 <- function(data, scale_column) {
  data %>%
    group_by(!!sym(scale_column)) %>%
    summarize(across(all_of(metric_list_FD), ~ calculate_adj_cv(.x), .names = "adj_cv_{col}")) %>%
    ungroup()  # Keep ungrouped so each row represents individual cells
}

#calculate adj CV
adjCV_75ha <- summarize_adj_cv2(stand_mets, "grid75") %>% mutate(scale = "75 ha")
adjCV_170ha <- summarize_adj_cv2(stand_mets, "grid170") %>% mutate(scale = "170 ha")
adjCV_650ha <- summarize_adj_cv2(stand_mets, "grid650") %>% mutate(scale = "650 ha")
adjCV_study_area <- summarize_adj_cv2(stand_mets, "study.area") %>% mutate(scale = "study area")
adjCV_partition <- summarize_adj_cv2(stand_mets, "partition") %>% mutate(scale = "partition")


#combine
adjCV_mets <- bind_rows(adjCV_75ha, adjCV_170ha, adjCV_650ha, adjCV_study_area, adjCV_partition)

#prep data for plotting
adjCV_mets_long <- adjCV_mets %>%
  pivot_longer(cols = starts_with("adj_cv_"), 
               names_to = "metric", 
               values_to = "value", 
               names_prefix = "adj_cv_") %>%
  mutate(metric_label = recode(metric, 
                               "mean.tree.h" = "tree h",
                               "rumple" = "rumple",
                               "zentropy" = "v dist.",
                               "lad.max" = "LAD",
                               "CRR.rho" = "CRR",
                               "ClosedGapSpace" = "gap vol.",
                               "vFRcanopy" = "veg. vol.",
                               "sd.r" = "tree h sd",
                               "max.height" = "tree h max.",
                               "stem.vol" = "tree vol.",
                               "mean.dbh" = "tree dbh",
                               "vzrumple" = "v complex.",
                               "stand.dens" = "tree dens.",
                               "basal.area" = "basal area",
                               "pts.below.2m" = "n pts<2m"))

#plot
adjCV_mets_long %>%
  filter(!metric %in% c("n.all", "shannon_ct", "div_even", "FRich", "FEven", "FDiver")) %>%
  mutate(scale = factor(scale, levels = c("75 ha", "170 ha", "650 ha", "study area", "partition"))) %>%
  ggplot(aes(x = scale, y = value, group = metric)) +
  geom_point(size = 2, shape = 1, color = "grey30", position = position_jitter(width = 0.1)) +
  stat_summary(fun = mean, geom = "line", aes(color = "mean trend"), size = 1) +
  stat_summary(data = . %>% filter(scale == "partition"),
               fun = mean, geom = "errorbarh", aes(xmax = 2.5, xmin = 1.5), 
               color = "forestgreen", size = 1.2, height = 0) +
  facet_wrap(~ metric_label, scales = "free_y") +
  labs(x = "grid scales (sq. km)", y = "adjusted coefficient of variation") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_x_discrete(labels = c("75 ha" = "0.75", 
                              "170 ha" = "1.7", 
                              "650 ha" = "6.5", 
                              "study area" = "26")) +
  scale_color_manual(values = c("mean trend" = "grey30"))
```



## Spatial scales in ecology lit

Using the publications (n = 192) reviewed in Stein et al. (2014) to explore the distribution of spatial scales in ecological research. Taxa include plants (pla), herps (her), invertebrates (inv), birds (bir), and mammals (mam).

```{r}
stein <- read.csv(file = "data/Stein_supp.csv", header = TRUE)
#head(stein)

stein <- stein[!duplicated(stein$ref),]

stein$taxon <- factor(stein$taxon, 
                      levels = rev(c("mam", "bir", "inv", "her", "pla", "mix")))

#table(stein$taxon)

ggplot(stein, aes(x = factor(grain), fill = taxon)) +
  geom_bar() +
  theme_classic() +
  labs(x = expression("spatial scale (in km"^2*")"),
       y = "n publications") +
  scale_fill_brewer(palette = "Set3") +
  scale_x_discrete(labels = c("1" = "≤ 0.01 ", 
                              "2" = "0.01 - 1", 
                              "3" = "1 - 100", 
                              "4" = "> 100"))
```

